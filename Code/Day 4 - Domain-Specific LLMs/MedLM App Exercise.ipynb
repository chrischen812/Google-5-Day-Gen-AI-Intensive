{"cells":[{"cell_type":"markdown","metadata":{"id":"b6e13eef3f5d"},"source":["##### Copyright 2024 Google LLC."]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","execution":{"iopub.execute_input":"2024-11-13T13:28:48.149451Z","iopub.status.busy":"2024-11-13T13:28:48.148175Z","iopub.status.idle":"2024-11-13T13:28:48.172942Z","shell.execute_reply":"2024-11-13T13:28:48.17169Z","shell.execute_reply.started":"2024-11-13T13:28:48.149391Z"},"id":"d6597b11df14","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{},"source":["### Query Med-Palm API"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T13:28:48.176078Z","iopub.status.busy":"2024-11-13T13:28:48.175384Z","iopub.status.idle":"2024-11-13T13:29:16.974112Z","shell.execute_reply":"2024-11-13T13:29:16.972754Z","shell.execute_reply.started":"2024-11-13T13:28:48.176022Z"},"id":"9wafTyEH1_xF","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: google-generativeai in c:\\users\\chris\\miniconda3\\lib\\site-packages (0.8.3)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (0.6.10)\n","Requirement already satisfied: google-api-core in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.22.0)\n","Requirement already satisfied: google-api-python-client in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.151.0)\n","Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.29.0)\n","Requirement already satisfied: protobuf in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (5.28.3)\n","Requirement already satisfied: pydantic in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.9.2)\n","Requirement already satisfied: tqdm in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n","Requirement already satisfied: typing-extensions in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.23.4)\n","Requirement already satisfied: colorama in c:\\users\\chris\\miniconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n"]}],"source":["%pip install  google-generativeai"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T13:29:16.976055Z","iopub.status.busy":"2024-11-13T13:29:16.975693Z","iopub.status.idle":"2024-11-13T13:29:18.197681Z","shell.execute_reply":"2024-11-13T13:29:18.196518Z","shell.execute_reply.started":"2024-11-13T13:29:16.976017Z"},"id":"T0CBG9xL2PvT","trusted":true},"outputs":[],"source":["import google.generativeai as genai\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P4bYX2T72ScK"},"source":["### Set up your API key\n","\n","To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n","\n","If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n","\n","To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","   \n","   \n","load_dotenv()\n","GOOGLE_API_KEY = os.getenv('VERTEXAI_API_KEY')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T13:29:18.200811Z","iopub.status.busy":"2024-11-13T13:29:18.200296Z","iopub.status.idle":"2024-11-13T13:29:18.503472Z","shell.execute_reply":"2024-11-13T13:29:18.502516Z","shell.execute_reply.started":"2024-11-13T13:29:18.200771Z"},"id":"VuJPY3GK2SLZ","trusted":true},"outputs":[],"source":["#from kaggle_secrets import UserSecretsClient\n","\n","#GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"CqVA5QFO6n4z"},"source":["### Explore available models\n","\n","You will be using the [`TunedModel.create`](https://ai.google.dev/api/tuning#method:-tunedmodels.create) API method to start the fine-tuning job and create your custom model. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about tuning models in [the model tuning docs](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python)."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["models/embedding-001\n","models/text-embedding-004\n"]}],"source":["for m in genai.list_models():\n","    if \"embedContent\" in m.supported_generation_methods:\n","        print(m.name)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["models/chat-bison-001\n","models/text-bison-001\n","models/embedding-gecko-001\n","models/gemini-1.0-pro-latest\n","models/gemini-1.0-pro\n","models/gemini-pro\n","models/gemini-1.0-pro-001\n","models/gemini-1.0-pro-vision-latest\n","models/gemini-pro-vision\n","models/gemini-1.5-pro-latest\n","models/gemini-1.5-pro-001\n","models/gemini-1.5-pro-002\n","models/gemini-1.5-pro\n","models/gemini-1.5-pro-exp-0801\n","models/gemini-1.5-pro-exp-0827\n","models/gemini-1.5-flash-latest\n","models/gemini-1.5-flash-001\n","models/gemini-1.5-flash-001-tuning\n","models/gemini-1.5-flash\n","models/gemini-1.5-flash-exp-0827\n","models/gemini-1.5-flash-002\n","models/gemini-1.5-flash-8b\n","models/gemini-1.5-flash-8b-001\n","models/gemini-1.5-flash-8b-latest\n","models/gemini-1.5-flash-8b-exp-0827\n","models/gemini-1.5-flash-8b-exp-0924\n","models/gemini-exp-1114\n","models/embedding-001\n","models/text-embedding-004\n","models/aqa\n"]}],"source":["model_list = [_ for _ in genai.list_models()]\n","for m in model_list:\n","    print(m.name)\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["import vertexai \n","\n","project_id = \"sublime-object-441904-n9\"\n","project_num = \"843583283103\"\n","\n","vertexai.init(project=project_id, location=\"us-central1\",api_key=GOOGLE_API_KEY)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_tools_lib', '_prepare_request', 'cached_content', 'count_tokens', 'count_tokens_async', 'from_cached_content', 'generate_content', 'generate_content_async', 'model_name', 'start_chat']\n","Help on class GenerativeModel in module google.generativeai.generative_models:\n","\n","class GenerativeModel(builtins.object)\n"," |  GenerativeModel(model_name: 'str' = 'gemini-1.5-flash-002', safety_settings: 'safety_types.SafetySettingOptions | None' = None, generation_config: 'generation_types.GenerationConfigType | None' = None, tools: 'content_types.FunctionLibraryType | None' = None, tool_config: 'content_types.ToolConfigType | None' = None, system_instruction: 'content_types.ContentType | None' = None)\n"," |  \n"," |  The `genai.GenerativeModel` class wraps default parameters for calls to\n"," |  `GenerativeModel.generate_content`, `GenerativeModel.count_tokens`, and\n"," |  `GenerativeModel.start_chat`.\n"," |  \n"," |  This family of functionality is designed to support multi-turn conversations, and multimodal\n"," |  requests. What media-types are supported for input and output is model-dependant.\n"," |  \n"," |  >>> import google.generativeai as genai\n"," |  >>> import PIL.Image\n"," |  >>> genai.configure(api_key='YOUR_API_KEY')\n"," |  >>> model = genai.GenerativeModel('models/gemini-pro')\n"," |  >>> result = model.generate_content('Tell me a story about a magic backpack')\n"," |  >>> result.text\n"," |  \"In the quaint little town of Lakeside, there lived a young girl named Lily...\"\n"," |  \n"," |  Multimodal input:\n"," |  \n"," |  >>> model = genai.GenerativeModel('models/gemini-pro')\n"," |  >>> result = model.generate_content([\n"," |  ...     \"Give me a recipe for these:\", PIL.Image.open('scones.jpeg')])\n"," |  >>> result.text\n"," |  \"**Blueberry Scones** ...\"\n"," |  \n"," |  Multi-turn conversation:\n"," |  \n"," |  >>> chat = model.start_chat()\n"," |  >>> response = chat.send_message(\"Hi, I have some questions for you.\")\n"," |  >>> response.text\n"," |  \"Sure, I'll do my best to answer your questions...\"\n"," |  \n"," |  To list the compatible model names use:\n"," |  \n"," |  >>> for m in genai.list_models():\n"," |  ...     if 'generateContent' in m.supported_generation_methods:\n"," |  ...         print(m.name)\n"," |  \n"," |  Arguments:\n"," |       model_name: The name of the model to query. To list compatible models use\n"," |       safety_settings: Sets the default safety filters. This controls which content is blocked\n"," |           by the api before being returned.\n"," |       generation_config: A `genai.GenerationConfig` setting the default generation parameters to\n"," |           use.\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, model_name: 'str' = 'gemini-1.5-flash-002', safety_settings: 'safety_types.SafetySettingOptions | None' = None, generation_config: 'generation_types.GenerationConfigType | None' = None, tools: 'content_types.FunctionLibraryType | None' = None, tool_config: 'content_types.ToolConfigType | None' = None, system_instruction: 'content_types.ContentType | None' = None)\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  __repr__ = __str__(self)\n"," |  \n"," |  __str__(self)\n"," |      Return str(self).\n"," |  \n"," |  count_tokens(self, contents: 'content_types.ContentsType' = None, *, generation_config: 'generation_types.GenerationConfigType | None' = None, safety_settings: 'safety_types.SafetySettingOptions | None' = None, tools: 'content_types.FunctionLibraryType | None' = None, tool_config: 'content_types.ToolConfigType | None' = None, request_options: 'helper_types.RequestOptionsType | None' = None) -> 'protos.CountTokensResponse'\n"," |      # fmt: off\n"," |  \n"," |  async count_tokens_async(self, contents: 'content_types.ContentsType' = None, *, generation_config: 'generation_types.GenerationConfigType | None' = None, safety_settings: 'safety_types.SafetySettingOptions | None' = None, tools: 'content_types.FunctionLibraryType | None' = None, tool_config: 'content_types.ToolConfigType | None' = None, request_options: 'helper_types.RequestOptionsType | None' = None) -> 'protos.CountTokensResponse'\n"," |  \n"," |  generate_content(self, contents: 'content_types.ContentsType', *, generation_config: 'generation_types.GenerationConfigType | None' = None, safety_settings: 'safety_types.SafetySettingOptions | None' = None, stream: 'bool' = False, tools: 'content_types.FunctionLibraryType | None' = None, tool_config: 'content_types.ToolConfigType | None' = None, request_options: 'helper_types.RequestOptionsType | None' = None) -> 'generation_types.GenerateContentResponse'\n"," |      A multipurpose function to generate responses from the model.\n"," |      \n"," |      This `GenerativeModel.generate_content` method can handle multimodal input, and multi-turn\n"," |      conversations.\n"," |      \n"," |      >>> model = genai.GenerativeModel('models/gemini-pro')\n"," |      >>> response = model.generate_content('Tell me a story about a magic backpack')\n"," |      >>> response.text\n"," |      \n"," |      ### Streaming\n"," |      \n"," |      This method supports streaming with the `stream=True`. The result has the same type as the non streaming case,\n"," |      but you can iterate over the response chunks as they become available:\n"," |      \n"," |      >>> response = model.generate_content('Tell me a story about a magic backpack', stream=True)\n"," |      >>> for chunk in response:\n"," |      ...   print(chunk.text)\n"," |      \n"," |      ### Multi-turn\n"," |      \n"," |      This method supports multi-turn chats but is **stateless**: the entire conversation history needs to be sent with each\n"," |      request. This takes some manual management but gives you complete control:\n"," |      \n"," |      >>> messages = [{'role':'user', 'parts': ['hello']}]\n"," |      >>> response = model.generate_content(messages) # \"Hello, how can I help\"\n"," |      >>> messages.append(response.candidates[0].content)\n"," |      >>> messages.append({'role':'user', 'parts': ['How does quantum physics work?']})\n"," |      >>> response = model.generate_content(messages)\n"," |      \n"," |      For a simpler multi-turn interface see `GenerativeModel.start_chat`.\n"," |      \n"," |      ### Input type flexibility\n"," |      \n"," |      While the underlying API strictly expects a `list[protos.Content]` objects, this method\n"," |      will convert the user input into the correct type. The hierarchy of types that can be\n"," |      converted is below. Any of these objects can be passed as an equivalent `dict`.\n"," |      \n"," |      * `Iterable[protos.Content]`\n"," |      * `protos.Content`\n"," |      * `Iterable[protos.Part]`\n"," |      * `protos.Part`\n"," |      * `str`, `Image`, or `protos.Blob`\n"," |      \n"," |      In an `Iterable[protos.Content]` each `content` is a separate message.\n"," |      But note that an `Iterable[protos.Part]` is taken as the parts of a single message.\n"," |      \n"," |      Arguments:\n"," |          contents: The contents serving as the model's prompt.\n"," |          generation_config: Overrides for the model's generation config.\n"," |          safety_settings: Overrides for the model's safety settings.\n"," |          stream: If True, yield response chunks as they are generated.\n"," |          tools: `protos.Tools` more info coming soon.\n"," |          request_options: Options for the request.\n"," |  \n"," |  async generate_content_async(self, contents: 'content_types.ContentsType', *, generation_config: 'generation_types.GenerationConfigType | None' = None, safety_settings: 'safety_types.SafetySettingOptions | None' = None, stream: 'bool' = False, tools: 'content_types.FunctionLibraryType | None' = None, tool_config: 'content_types.ToolConfigType | None' = None, request_options: 'helper_types.RequestOptionsType | None' = None) -> 'generation_types.AsyncGenerateContentResponse'\n"," |      The async version of `GenerativeModel.generate_content`.\n"," |  \n"," |  start_chat(self, *, history: 'Iterable[content_types.StrictContentType] | None' = None, enable_automatic_function_calling: 'bool' = False) -> 'ChatSession'\n"," |      Returns a `genai.ChatSession` attached to this model.\n"," |      \n"," |      >>> model = genai.GenerativeModel()\n"," |      >>> chat = model.start_chat(history=[...])\n"," |      >>> response = chat.send_message(\"Hello?\")\n"," |      \n"," |      Arguments:\n"," |          history: An iterable of `protos.Content` objects, or equivalents to initialize the session.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Class methods defined here:\n"," |  \n"," |  from_cached_content(cached_content: 'str | caching.CachedContent', *, generation_config: 'generation_types.GenerationConfigType | None' = None, safety_settings: 'safety_types.SafetySettingOptions | None' = None) -> 'GenerativeModel' from builtins.type\n"," |      Creates a model with `cached_content` as model's context.\n"," |      \n"," |      Args:\n"," |          cached_content: context for the model.\n"," |          generation_config: Overrides for the model's generation config.\n"," |          safety_settings: Overrides for the model's safety settings.\n"," |      \n"," |      Returns:\n"," |          `GenerativeModel` object with `cached_content` as its context.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Readonly properties defined here:\n"," |  \n"," |  cached_content\n"," |  \n"," |  model_name\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n"]}],"source":["print(dir(genai.GenerativeModel))\n","help(genai.GenerativeModel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#help(vertexai.generative_models.GenerativeModel.generate_content)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["An error occurred: HTTP Error 400: Bad Request\n"]}],"source":["from pytube import YouTube\n","from pytube.exceptions import VideoUnavailable\n","\n","# Function to download a YouTube video\n","def download_youtube_video(video_url, output_path='.', filename=None):\n","    try:\n","        # Create a YouTube object\n","        yt = YouTube(video_url)\n","\n","        # Select the highest resolution stream available\n","        stream = yt.streams.get_highest_resolution()\n","\n","        # If a filename is provided, use it; otherwise, use the default title\n","        if filename is None:\n","            filename = yt.title + '.mp4'\n","\n","        # Download the video\n","        stream.download(output_path=output_path, filename=filename)\n","        print(f\"Download complete: {filename}\")\n","\n","    except VideoUnavailable:\n","        print(\"The video is unavailable.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    video_url = \"https://www.youtube.com/watch?v=61N3r1RlSxU\"  # Replace with your video URL\n","    download_youtube_video(video_url, output_path='C:/Users/chris/Downloads')  # Specify your output path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#from vertexai.generative_models import GenerativeModel\n","\n","for m in vertexai.list_models():\n","    print(m.name)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Text generation: basic"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"ename":"GoogleAuthError","evalue":"\nUnable to authenticate your request.\nDepending on your runtime environment, you can complete authentication by:\n- if in local JupyterLab instance: `!gcloud auth login` \n- if in Colab:\n    -`from google.colab import auth`\n    -`auth.authenticate_user()`\n- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\initializer.py:356\u001b[0m, in \u001b[0;36m_Config.project\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_project_as_env_var_or_google_auth_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m     project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\initializer.py:112\u001b[0m, in \u001b[0;36m_Config._set_project_as_env_var_or_google_auth_default\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     credentials, project \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;129;01mor\u001b[39;00m credentials\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\auth\\_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n","\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mGoogleAuthError\u001b[0m                           Traceback (most recent call last)","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:289\u001b[0m, in \u001b[0;36m_ModelGardenModel.from_pretrained\u001b[1;34m(cls, model_name)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterface_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m auth_exceptions\u001b[38;5;241m.\u001b[39mGoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:206\u001b[0m, in \u001b[0;36m_from_pretrained\u001b[1;34m(interface_class, model_name, publisher_model, tuned_vertex_model)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    203\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterface_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a correct model interface class since it does not have an instance schema URI.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m         )\n\u001b[1;32m--> 206\u001b[0m     model_info \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_to_class_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43minterface_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_INSTANCE_SCHEMA_URI\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface_class\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:122\u001b[0m, in \u001b[0;36m_get_model_info\u001b[1;34m(model_id, schema_to_class_map, interface_class, publisher_model_res, tuned_vertex_model)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m publisher_model_res:\n\u001b[0;32m    121\u001b[0m     publisher_model_res \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 122\u001b[0m         \u001b[43m_publisher_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_PublisherModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_gca_resource\n\u001b[0;32m    125\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m publisher_model_res\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublishers/google/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\_publisher_models.py:63\u001b[0m, in \u001b[0;36m_PublisherModel.__init__\u001b[1;34m(self, resource_name, project, location, credentials)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves an existing PublisherModel resource given a resource name or model garden id.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m        Overrides credentials set in aiplatform.init.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_resource_name(resource_name):\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\base.py:556\u001b[0m, in \u001b[0;36mVertexAiResourceNoun.__init__\u001b[1;34m(self, project, location, credentials, resource_name)\u001b[0m\n\u001b[0;32m    552\u001b[0m     project, location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_and_validate_project_location(\n\u001b[0;32m    553\u001b[0m         resource_name\u001b[38;5;241m=\u001b[39mresource_name, project\u001b[38;5;241m=\u001b[39mproject, location\u001b[38;5;241m=\u001b[39mlocation\n\u001b[0;32m    554\u001b[0m     )\n\u001b[1;32m--> 556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject \u001b[38;5;241m=\u001b[39m project \u001b[38;5;129;01mor\u001b[39;00m \u001b[43minitializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m location \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mlocation\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\initializer.py:359\u001b[0m, in \u001b[0;36m_Config.project\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GoogleAuthError(project_not_found_exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m project_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key:\n","\u001b[1;31mGoogleAuthError\u001b[0m: Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mGoogleAuthError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the model (replace with actual model name if needed)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_name1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/text-bison-001\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mTextGenerationModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mpredict(prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the symptoms of the common cold?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#response = model1.predict( prompt=prompt,temperature=0.1,max_output_tokens=800,top_p=1.0,top_k=40 )\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:291\u001b[0m, in \u001b[0;36m_ModelGardenModel.from_pretrained\u001b[1;34m(cls, model_name)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_pretrained(interface_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, model_name\u001b[38;5;241m=\u001b[39mmodel_name)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m auth_exceptions\u001b[38;5;241m.\u001b[39mGoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m auth_exceptions\u001b[38;5;241m.\u001b[39mGoogleAuthError(credential_exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[1;31mGoogleAuthError\u001b[0m: \nUnable to authenticate your request.\nDepending on your runtime environment, you can complete authentication by:\n- if in local JupyterLab instance: `!gcloud auth login` \n- if in Colab:\n    -`from google.colab import auth`\n    -`auth.authenticate_user()`\n- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication"]}],"source":["#PaLM\n","from vertexai.language_models import TextGenerationModel \n","\n","# Initialize the model (replace with actual model name if needed)\n","model_name1 = 'models/text-bison-001'\n","\n","model1 = TextGenerationModel.from_pretrained(model_name1)\n","\n","response = model1.predict(prompt=\"What are the symptoms of the common cold?\")\n","#response = model1.predict( prompt=prompt,temperature=0.1,max_output_tokens=800,top_p=1.0,top_k=40 )\n","print(response.text)\n"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: timed out\n","WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: timed out\n","WARNING:google.auth.compute_engine._metadata:Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: timed out\n"]},{"ename":"DefaultCredentialsError","evalue":"Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)","Cell \u001b[1;32mIn[55], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model2 \u001b[38;5;241m=\u001b[39m GenerativeModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.0-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      5\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the symptoms of the common cold?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#responses = model2.generate_content(prompt,generation_config={ \"temperature\": 0.1,\"max_output_tokens\": 800,\"top_p\": 1.0,\"top_k\": 40,} )\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses: \n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\vertexai\\generative_models\\_generative_models.py:654\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[0;32m    646\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    647\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    652\u001b[0m     )\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\vertexai\\generative_models\\_generative_models.py:779\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    771\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m    772\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[0;32m    773\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m    778\u001b[0m )\n\u001b[1;32m--> 779\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate_content(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\vertexai\\generative_models\\_generative_models.py:3165\u001b[0m, in \u001b[0;36mGenerativeModel._prediction_client\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3156\u001b[0m         aiplatform_initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[0;32m   3157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m aiplatform_initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mproject\n\u001b[0;32m   3158\u001b[0m     ):\n\u001b[0;32m   3159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApi keys are only supported with the preview namespace. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3161\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImport the preview namespace instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom vertexai.preview import generative_models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3163\u001b[0m         )\n\u001b[0;32m   3164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_client_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 3165\u001b[0m         \u001b[43maiplatform_initializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclient_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_service_v1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPredictionServiceClient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3167\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocation_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprediction_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3169\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3170\u001b[0m     )\n\u001b[0;32m   3171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_client_value\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\initializer.py:622\u001b[0m, in \u001b[0;36m_Config.create_client\u001b[1;34m(self, client_class, credentials, location_override, prediction_client, api_base_path_override, api_key, api_path_override, appended_user_agent, appended_gapic_version)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_transport \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;66;03m# User requests sync REST\u001b[39;00m\n\u001b[0;32m    620\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_transport\n\u001b[1;32m--> 622\u001b[0m client \u001b[38;5;241m=\u001b[39m client_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;66;03m# We only wrap the client if the request_metadata is set at the creation time.\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_metadata:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:710\u001b[0m, in \u001b[0;36mPredictionServiceClient.__init__\u001b[1;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[0;32m    705\u001b[0m     credentials \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39m_default\u001b[38;5;241m.\u001b[39mget_api_key_credentials(\n\u001b[0;32m    706\u001b[0m         api_key_value\n\u001b[0;32m    707\u001b[0m     )\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\grpc.py:158\u001b[0m, in \u001b[0;36mPredictionServiceGrpcTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[0;32m    154\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[0;32m    155\u001b[0m             )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\base.py:108\u001b[0m, in \u001b[0;36mPredictionServiceTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[0;32m    105\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m    106\u001b[0m     )\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[1;32m--> 108\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault(\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\auth\\_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    683\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[0;32m    688\u001b[0m             )\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n","\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."]}],"source":["#Gemini\n","from vertexai.generative_models import GenerativeModel\n","\n","model2 = GenerativeModel(\"gemini-1.0-pro\") \n","prompt = \"What are the symptoms of the common cold?\"\n","responses = model2.generate_content(prompt) \n","#responses = model2.generate_content(prompt,generation_config={ \"temperature\": 0.1,\"max_output_tokens\": 800,\"top_p\": 1.0,\"top_k\": 40,} )\n","for response in responses: \n","    print(response.text)"]},{"cell_type":"markdown","metadata":{},"source":["### Chat"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#PaLM\n","from vertexai.language_models import ChatModel\n","\n","model3 = ChatModel.from_pretrained(\"chat-bison@002\")\n","\n","chat = model3.start_chat()\n","\n","print(\n","    chat.send_message(\n","        \"\"\"\n","Hello! Can you write a 300 word abstract for a research paper I need to write about the impact of AI on society?\n","\"\"\"\n","    )\n",")\n","\n","print(\n","    chat.send_message(\n","        \"\"\"\n","Could you give me a catchy title for the paper?\n","\"\"\"\n","    )\n",")\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Gemini\n","from vertexai.generative_models import GenerativeModel\n","\n","model4 = GenerativeModel(\"gemini-1.0-pro\")\n","\n","chat = model4.start_chat()\n","\n","\n","responses = chat.send_message(\n","        \"\"\"\n","Hello! Can you write a 300 word abstract for a research paper I need to write about the impact of AI on society?\n","\"\"\"\n","    )\n","\n","for response in responses:\n","   print(response.text)\n","\n","\n","responses = chat.send_message(\n","        \"\"\"\n","Could you give me a catchy title for the paper?\n","\"\"\"\n","    )\n","\n","for response in responses:\n","   print(response.text)\n","        "]}],"metadata":{"colab":{"name":"day-4-fine-tuning-a-custom-model.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}

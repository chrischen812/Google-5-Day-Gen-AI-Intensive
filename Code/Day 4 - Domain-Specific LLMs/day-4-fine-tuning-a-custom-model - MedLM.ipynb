{"cells":[{"cell_type":"markdown","metadata":{"id":"b6e13eef3f5d"},"source":["##### Copyright 2024 Google LLC."]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","execution":{"iopub.execute_input":"2024-11-13T13:28:48.149451Z","iopub.status.busy":"2024-11-13T13:28:48.148175Z","iopub.status.idle":"2024-11-13T13:28:48.172942Z","shell.execute_reply":"2024-11-13T13:28:48.17169Z","shell.execute_reply.started":"2024-11-13T13:28:48.149391Z"},"id":"d6597b11df14","jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"4KDIFPAL2EnL"},"source":["# Day 4 - Fine tuning a custom model\n","\n","Welcome back to the Kaggle 5-day Generative AI course!\n","\n","In this notebook you will use the Gemini API to fine-tune a custom, task-specific model. Fine-tuning can be used for a variety of tasks from classic NLP problems like entity extraction or summarisation, to creative tasks like stylised generation. You will fine-tune a model to classify the category a piece of text (a newsgroup post) into the category it belongs to (the newsgroup name).\n","\n","This codelab walks you tuning a model with the API. [AI Studio](https://aistudio.google.com/app/tune) also supports creating new tuned models directly in the web UI, allowing you to quickly create and monitor models using data from Google Sheets, Drive or your own files."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T13:28:48.176078Z","iopub.status.busy":"2024-11-13T13:28:48.175384Z","iopub.status.idle":"2024-11-13T13:29:16.974112Z","shell.execute_reply":"2024-11-13T13:29:16.972754Z","shell.execute_reply.started":"2024-11-13T13:28:48.176022Z"},"id":"9wafTyEH1_xF","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: google-generativeai in c:\\users\\chris\\miniconda3\\lib\\site-packages (0.8.3)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (0.6.10)\n","Requirement already satisfied: google-api-core in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.22.0)\n","Requirement already satisfied: google-api-python-client in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.151.0)\n","Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.29.0)\n","Requirement already satisfied: protobuf in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (5.28.3)\n","Requirement already satisfied: pydantic in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (2.9.2)\n","Requirement already satisfied: tqdm in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n","Requirement already satisfied: typing-extensions in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.23.4)\n","Requirement already satisfied: colorama in c:\\users\\chris\\miniconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n"]}],"source":["%pip install  google-generativeai"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T13:29:16.976055Z","iopub.status.busy":"2024-11-13T13:29:16.975693Z","iopub.status.idle":"2024-11-13T13:29:18.197681Z","shell.execute_reply":"2024-11-13T13:29:18.196518Z","shell.execute_reply.started":"2024-11-13T13:29:16.976017Z"},"id":"T0CBG9xL2PvT","trusted":true},"outputs":[],"source":["import google.generativeai as genai\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P4bYX2T72ScK"},"source":["### Set up your API key\n","\n","To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n","\n","If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n","\n","To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","   \n","   \n","load_dotenv()\n","GOOGLE_API_KEY = os.getenv('VERTEXAI_API_KEY')"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-11-13T13:29:18.200811Z","iopub.status.busy":"2024-11-13T13:29:18.200296Z","iopub.status.idle":"2024-11-13T13:29:18.503472Z","shell.execute_reply":"2024-11-13T13:29:18.502516Z","shell.execute_reply.started":"2024-11-13T13:29:18.200771Z"},"id":"VuJPY3GK2SLZ","trusted":true},"outputs":[],"source":["#from kaggle_secrets import UserSecretsClient\n","\n","#GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"25b2127c2052"},"source":["If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n","\n","![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"]},{"cell_type":"markdown","metadata":{"id":"CqVA5QFO6n4z"},"source":["### Explore available models\n","\n","You will be using the [`TunedModel.create`](https://ai.google.dev/api/tuning#method:-tunedmodels.create) API method to start the fine-tuning job and create your custom model. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about tuning models in [the model tuning docs](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python)."]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model(name='models/chat-bison-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='PaLM 2 Chat (Legacy)',\n","      description='A legacy text-only model optimized for chat conversations',\n","      input_token_limit=4096,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n","      temperature=0.25,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/text-bison-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='PaLM 2 (Legacy)',\n","      description='A legacy model that understands text and generates text as an output',\n","      input_token_limit=8196,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n","      temperature=0.7,\n","      max_temperature=None,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/embedding-gecko-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Embedding Gecko',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=1024,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedText', 'countTextTokens'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Latest',\n","      description=('The best model for scaling across a wide range of tasks. This is the latest '\n","                   'model.'),\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro',\n","      description='The best model for scaling across a wide range of tasks',\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-pro',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro',\n","      description='The best model for scaling across a wide range of tasks',\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro 001 (Tuning)',\n","      description=('The best model for scaling across a wide range of tasks. This is a stable '\n","                   'model that supports tuning.'),\n","      input_token_limit=30720,\n","      output_token_limit=2048,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n","      temperature=0.9,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=None)\n","Model(name='models/gemini-1.0-pro-vision-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Vision',\n","      description='The best image understanding model to handle a broad range of applications',\n","      input_token_limit=12288,\n","      output_token_limit=4096,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.4,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=32)\n","Model(name='models/gemini-pro-vision',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.0 Pro Vision',\n","      description='The best image understanding model to handle a broad range of applications',\n","      input_token_limit=12288,\n","      output_token_limit=4096,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=0.4,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=32)\n","Model(name='models/gemini-1.5-pro-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro Latest',\n","      description='Mid-size multimodal model that supports up to 2 million tokens',\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro 001',\n","      description='Mid-size multimodal model that supports up to 2 million tokens',\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-pro-002',\n","      base_model_id='',\n","      version='002',\n","      display_name='Gemini 1.5 Pro 002',\n","      description='Mid-size multimodal model that supports up to 2 million tokens',\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Pro',\n","      description='Mid-size multimodal model that supports up to 2 million tokens',\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-pro-exp-0801',\n","      base_model_id='',\n","      version='exp-0801',\n","      display_name='Gemini 1.5 Pro Experimental 0801',\n","      description='Mid-size multimodal model that supports up to 2 million tokens',\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-pro-exp-0827',\n","      base_model_id='',\n","      version='exp-0827',\n","      display_name='Gemini 1.5 Pro Experimental 0827',\n","      description='Mid-size multimodal model that supports up to 2 million tokens',\n","      input_token_limit=2000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash Latest',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 001',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash-001-tuning',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 001 Tuning',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=16384,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-exp-0827',\n","      base_model_id='',\n","      version='exp-0827',\n","      display_name='Gemini 1.5 Flash Experimental 0827',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/gemini-1.5-flash-002',\n","      base_model_id='',\n","      version='002',\n","      display_name='Gemini 1.5 Flash 002',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B 001',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-latest',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash-8B Latest',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-exp-0827',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 8B Experimental 0827',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-1.5-flash-8b-exp-0924',\n","      base_model_id='',\n","      version='001',\n","      display_name='Gemini 1.5 Flash 8B Experimental 0924',\n","      description='Fast and versatile multimodal model for scaling across diverse tasks',\n","      input_token_limit=1000000,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=40)\n","Model(name='models/gemini-exp-1114',\n","      base_model_id='',\n","      version='exp-1114',\n","      display_name='Gemini Experimental 1114',\n","      description='Mid-size multimodal model that supports up to 2 million tokens',\n","      input_token_limit=32767,\n","      output_token_limit=8192,\n","      supported_generation_methods=['generateContent', 'countTokens'],\n","      temperature=1.0,\n","      max_temperature=2.0,\n","      top_p=0.95,\n","      top_k=64)\n","Model(name='models/embedding-001',\n","      base_model_id='',\n","      version='001',\n","      display_name='Embedding 001',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=2048,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/text-embedding-004',\n","      base_model_id='',\n","      version='004',\n","      display_name='Text Embedding 004',\n","      description='Obtain a distributed representation of a text.',\n","      input_token_limit=2048,\n","      output_token_limit=1,\n","      supported_generation_methods=['embedContent'],\n","      temperature=None,\n","      max_temperature=None,\n","      top_p=None,\n","      top_k=None)\n","Model(name='models/aqa',\n","      base_model_id='',\n","      version='001',\n","      display_name='Model that performs Attributed Question Answering.',\n","      description=('Model trained to return answers to questions that are grounded in provided '\n","                   'sources, along with estimating answerable probability.'),\n","      input_token_limit=7168,\n","      output_token_limit=1024,\n","      supported_generation_methods=['generateAnswer'],\n","      temperature=0.2,\n","      max_temperature=None,\n","      top_p=1.0,\n","      top_k=40)\n"]}],"source":["try:\n","    models_generator = genai.list_models()\n","    \n","    # Convert the generator to a list to print all models\n","    models = list(models_generator)\n","    \n","    # Print each model\n","    for model in models:\n","        print(model)\n","except Exception as e:\n","    print(f\"An error occurred while listing models: {e}\")\n"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"generate_content() got an unexpected keyword argument 'prompt'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[64], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(model_name)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Use dir() to list all attributes and methods\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#print(dir(model))\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#help(model.generate_content)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are the symptoms of the common cold?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n","\u001b[1;31mTypeError\u001b[0m: generate_content() got an unexpected keyword argument 'prompt'"]}],"source":["# Assuming you have already imported the necessary module and initialized the model\n","import google.generativeai as genai\n","\n","# Initialize the model (replace with actual model name if needed)\n","model_name = 'models/text-bison-001'\n","model = genai.GenerativeModel(model_name)\n","\n","# Use dir() to list all attributes and methods\n","#print(dir(model))\n","#help(model.generate_content)\n","response = model.generate_content(prompt=\"What are the symptoms of the common cold?\")\n","print(response.text)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting google-cloud-aiplatform\n","  Downloading google_cloud_aiplatform-1.72.0-py2.py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.22.0)\n","Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-cloud-aiplatform) (2.29.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-cloud-aiplatform) (1.25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-cloud-aiplatform) (5.28.3)\n","Requirement already satisfied: packaging>=14.3 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-cloud-aiplatform) (23.2)\n","Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n","  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n","Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n","  Downloading google_cloud_bigquery-3.27.0-py2.py3-none-any.whl.metadata (8.6 kB)\n","Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n","  Downloading google_cloud_resource_manager-1.13.1-py2.py3-none-any.whl.metadata (5.4 kB)\n","Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n","  Downloading shapely-2.0.6-cp39-cp39-win_amd64.whl.metadata (7.2 kB)\n","Requirement already satisfied: pydantic<3 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-cloud-aiplatform) (2.9.2)\n","Collecting docstring-parser<1 (from google-cloud-aiplatform)\n","  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n","Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n","  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n","Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n","  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n","Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0)\n","Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n","  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n","Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n","  Downloading google_crc32c-1.6.0-cp39-cp39-win_amd64.whl.metadata (2.4 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.11.0)\n","Requirement already satisfied: numpy<3,>=1.14 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\miniconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n","Downloading google_cloud_aiplatform-1.72.0-py2.py3-none-any.whl (6.2 MB)\n","   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n","    --------------------------------------- 0.2/6.2 MB 4.5 MB/s eta 0:00:02\n","   -- ------------------------------------- 0.3/6.2 MB 4.1 MB/s eta 0:00:02\n","   -- ------------------------------------- 0.5/6.2 MB 3.5 MB/s eta 0:00:02\n","   ---- ----------------------------------- 0.6/6.2 MB 4.0 MB/s eta 0:00:02\n","   ----- ---------------------------------- 0.8/6.2 MB 3.7 MB/s eta 0:00:02\n","   ------ --------------------------------- 1.0/6.2 MB 3.7 MB/s eta 0:00:02\n","   ------- -------------------------------- 1.2/6.2 MB 3.8 MB/s eta 0:00:02\n","   -------- ------------------------------- 1.4/6.2 MB 3.8 MB/s eta 0:00:02\n","   --------- ------------------------------ 1.5/6.2 MB 3.7 MB/s eta 0:00:02\n","   ---------- ----------------------------- 1.7/6.2 MB 3.6 MB/s eta 0:00:02\n","   ------------ --------------------------- 1.9/6.2 MB 3.6 MB/s eta 0:00:02\n","   ------------- -------------------------- 2.0/6.2 MB 3.6 MB/s eta 0:00:02\n","   -------------- ------------------------- 2.2/6.2 MB 3.7 MB/s eta 0:00:02\n","   -------------- ------------------------- 2.2/6.2 MB 3.6 MB/s eta 0:00:02\n","   -------------- ------------------------- 2.3/6.2 MB 3.3 MB/s eta 0:00:02\n","   --------------- ------------------------ 2.4/6.2 MB 3.4 MB/s eta 0:00:02\n","   ----------------- ---------------------- 2.7/6.2 MB 3.4 MB/s eta 0:00:02\n","   ------------------ --------------------- 2.8/6.2 MB 3.5 MB/s eta 0:00:01\n","   ------------------- -------------------- 3.0/6.2 MB 3.5 MB/s eta 0:00:01\n","   -------------------- ------------------- 3.2/6.2 MB 3.5 MB/s eta 0:00:01\n","   --------------------- ------------------ 3.3/6.2 MB 3.4 MB/s eta 0:00:01\n","   --------------------- ------------------ 3.3/6.2 MB 3.4 MB/s eta 0:00:01\n","   ---------------------- ----------------- 3.5/6.2 MB 3.3 MB/s eta 0:00:01\n","   ------------------------ --------------- 3.7/6.2 MB 3.3 MB/s eta 0:00:01\n","   ------------------------- -------------- 3.9/6.2 MB 3.4 MB/s eta 0:00:01\n","   -------------------------- ------------- 4.1/6.2 MB 3.3 MB/s eta 0:00:01\n","   --------------------------- ------------ 4.2/6.2 MB 3.4 MB/s eta 0:00:01\n","   ---------------------------- ----------- 4.4/6.2 MB 3.4 MB/s eta 0:00:01\n","   ----------------------------- ---------- 4.5/6.2 MB 3.4 MB/s eta 0:00:01\n","   ------------------------------ --------- 4.7/6.2 MB 3.4 MB/s eta 0:00:01\n","   ------------------------------- -------- 4.9/6.2 MB 3.4 MB/s eta 0:00:01\n","   -------------------------------- ------- 5.0/6.2 MB 3.4 MB/s eta 0:00:01\n","   --------------------------------- ------ 5.2/6.2 MB 3.4 MB/s eta 0:00:01\n","   ---------------------------------- ----- 5.4/6.2 MB 3.4 MB/s eta 0:00:01\n","   ----------------------------------- ---- 5.6/6.2 MB 3.5 MB/s eta 0:00:01\n","   ------------------------------------- -- 5.8/6.2 MB 3.5 MB/s eta 0:00:01\n","   -------------------------------------- - 6.0/6.2 MB 3.5 MB/s eta 0:00:01\n","   ---------------------------------------  6.1/6.2 MB 3.5 MB/s eta 0:00:01\n","   ---------------------------------------- 6.2/6.2 MB 3.4 MB/s eta 0:00:00\n","Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n","Downloading google_cloud_bigquery-3.27.0-py2.py3-none-any.whl (240 kB)\n","   ---------------------------------------- 0.0/240.1 kB ? eta -:--:--\n","   ------------------------- -------------- 153.6/240.1 kB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------- 240.1/240.1 kB 3.7 MB/s eta 0:00:00\n","Downloading google_cloud_resource_manager-1.13.1-py2.py3-none-any.whl (358 kB)\n","   ---------------------------------------- 0.0/358.6 kB ? eta -:--:--\n","   ----------------- ---------------------- 153.6/358.6 kB 4.6 MB/s eta 0:00:01\n","   ------------------------------------- -- 337.9/358.6 kB 3.5 MB/s eta 0:00:01\n","   ---------------------------------------- 358.6/358.6 kB 3.2 MB/s eta 0:00:00\n","Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n","   ---------------------------------------- 0.0/130.5 kB ? eta -:--:--\n","   ------------------------------------- -- 122.9/130.5 kB 3.6 MB/s eta 0:00:01\n","   ---------------------------------------- 130.5/130.5 kB 2.6 MB/s eta 0:00:00\n","Downloading shapely-2.0.6-cp39-cp39-win_amd64.whl (1.4 MB)\n","   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n","   ---- ----------------------------------- 0.2/1.4 MB 4.5 MB/s eta 0:00:01\n","   --------- ------------------------------ 0.3/1.4 MB 4.3 MB/s eta 0:00:01\n","   -------------- ------------------------- 0.5/1.4 MB 3.7 MB/s eta 0:00:01\n","   -------------------- ------------------- 0.7/1.4 MB 3.8 MB/s eta 0:00:01\n","   ------------------------- -------------- 0.9/1.4 MB 3.8 MB/s eta 0:00:01\n","   ------------------------------ --------- 1.1/1.4 MB 3.9 MB/s eta 0:00:01\n","   ----------------------------------- ---- 1.3/1.4 MB 3.9 MB/s eta 0:00:01\n","   ---------------------------------------- 1.4/1.4 MB 3.8 MB/s eta 0:00:00\n","Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n","Downloading google_crc32c-1.6.0-cp39-cp39-win_amd64.whl (33 kB)\n","Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n","   ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n","   ---------------------------------------- 81.3/81.3 kB 2.3 MB/s eta 0:00:00\n","Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n","Installing collected packages: shapely, google-crc32c, docstring-parser, google-resumable-media, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n","Successfully installed docstring-parser-0.16 google-cloud-aiplatform-1.72.0 google-cloud-bigquery-3.27.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.13.1 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 grpc-google-iam-v1-0.13.1 shapely-2.0.6\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n","  WARNING: The script tb-gcp-uploader.exe is installed in 'C:\\Users\\chris\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'vertexai'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 install --upgrade --user google-cloud-aiplatform\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvertexai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreview\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextGenerationModel\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vertexai'"]}],"source":["!pip3 install --upgrade --user google-cloud-aiplatform\n","from vertexai.preview.language_models import TextGenerationModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","def interview(temperature: float = .2):\n","    \"\"\"Ideation example with a Large Language Model\"\"\"\n","\n","    # TODO developer - override these parameters as needed:\n","    parameters = {\n","        \"temperature\": temperature,\n","        \"max_output_tokens\": 256,\n","        \"top_p\": .8,\n","        \"top_k\": 40,\n","    }\n","\n","    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n","    response = model.predict(\n","        'Give me ten interview questions for the role of program manager.',\n","        **parameters,\n","    )\n","    print(f\"Response from Model: {response.text}\")"]}],"metadata":{"colab":{"name":"day-4-fine-tuning-a-custom-model.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}

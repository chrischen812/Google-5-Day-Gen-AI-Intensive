{"cells":[{"cell_type":"markdown","metadata":{"id":"v0WeWbFNkUSz"},"source":["##### Copyright 2024 Google LLC."]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","execution":{"iopub.execute_input":"2024-11-08T20:12:05.316321Z","iopub.status.busy":"2024-11-08T20:12:05.315901Z","iopub.status.idle":"2024-11-08T20:12:05.338383Z","shell.execute_reply":"2024-11-08T20:12:05.337083Z","shell.execute_reply.started":"2024-11-08T20:12:05.316282Z"},"id":"Aqwsgz9lkUst","trusted":true},"outputs":[],"source":["# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"bhT1u-Pof10V"},"source":["# Day 2 - Classifying embeddings with Keras and the Gemini API\n","\n","## Overview\n","\n","Welcome back to the Kaggle 5-day Generative AI course. In this notebook, you'll learn to use the embeddings produced by the Gemini API to train a model that can classify newsgroup posts into the categories (the newsgroup itself) from the post contents.\n","\n","This technique uses the Gemini API's embeddings as input, avoiding the need to train on text input directly, and as a result it is able to perform quite well using relatively few examples compared to training a text model from scratch.\n","\n","## For help\n","\n","**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:05.342871Z","iopub.status.busy":"2024-11-08T20:12:05.342436Z","iopub.status.idle":"2024-11-08T20:12:33.806342Z","shell.execute_reply":"2024-11-08T20:12:33.805044Z","shell.execute_reply.started":"2024-11-08T20:12:05.342817Z"},"id":"FXq0ygI3BCdQ","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -U -q \"google-generativeai>=0.8.3\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:33.80929Z","iopub.status.busy":"2024-11-08T20:12:33.808193Z","iopub.status.idle":"2024-11-08T20:12:35.015951Z","shell.execute_reply":"2024-11-08T20:12:35.014608Z","shell.execute_reply.started":"2024-11-08T20:12:33.809232Z"},"id":"XiJjB2vWCQJP","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\chris\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import google.generativeai as genai"]},{"cell_type":"markdown","metadata":{"id":"_mwJYXpElYJc"},"source":["### Set up your API key\n","\n","To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n","\n","If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n","\n","To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":[" import os\n"," from dotenv import load_dotenv\n","   \n","   \n","load_dotenv()\n","GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:35.02012Z","iopub.status.busy":"2024-11-08T20:12:35.019127Z","iopub.status.idle":"2024-11-08T20:12:35.236291Z","shell.execute_reply":"2024-11-08T20:12:35.235045Z","shell.execute_reply.started":"2024-11-08T20:12:35.020065Z"},"id":"tayrk_A2lZ7A","trusted":true},"outputs":[],"source":["#from kaggle_secrets import UserSecretsClient\n","\n","#GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"c79728739642"},"source":["If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n","\n","![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"]},{"cell_type":"markdown","metadata":{"id":"C5B9sWq0hNEV"},"source":["## Dataset\n","\n","The [20 Newsgroups Text Dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contains 18,000 newsgroups posts on 20 topics divided into training and test sets. The split between the training and test datasets are based on messages posted before and after a specific date. For this tutorial, you will use sampled subsets of the training and test sets, and perform some processing using Pandas."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:35.238364Z","iopub.status.busy":"2024-11-08T20:12:35.237942Z","iopub.status.idle":"2024-11-08T20:12:45.162344Z","shell.execute_reply":"2024-11-08T20:12:45.161263Z","shell.execute_reply.started":"2024-11-08T20:12:35.238326Z"},"id":"jDoKis4om-Ea","trusted":true},"outputs":[{"data":{"text/plain":["['alt.atheism',\n"," 'comp.graphics',\n"," 'comp.os.ms-windows.misc',\n"," 'comp.sys.ibm.pc.hardware',\n"," 'comp.sys.mac.hardware',\n"," 'comp.windows.x',\n"," 'misc.forsale',\n"," 'rec.autos',\n"," 'rec.motorcycles',\n"," 'rec.sport.baseball',\n"," 'rec.sport.hockey',\n"," 'sci.crypt',\n"," 'sci.electronics',\n"," 'sci.med',\n"," 'sci.space',\n"," 'soc.religion.christian',\n"," 'talk.politics.guns',\n"," 'talk.politics.mideast',\n"," 'talk.politics.misc',\n"," 'talk.religion.misc']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.datasets import fetch_20newsgroups\n","\n","newsgroups_train = fetch_20newsgroups(subset=\"train\")\n","newsgroups_test = fetch_20newsgroups(subset=\"test\")\n","\n","# View list of class names for dataset\n","newsgroups_train.target_names"]},{"cell_type":"markdown","metadata":{"id":"hDz9MjkNl_FD"},"source":["Here is an example of what a record from the training set looks like."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:45.164162Z","iopub.status.busy":"2024-11-08T20:12:45.16375Z","iopub.status.idle":"2024-11-08T20:12:45.169636Z","shell.execute_reply":"2024-11-08T20:12:45.168506Z","shell.execute_reply.started":"2024-11-08T20:12:45.164125Z"},"id":"FPq-56AimOPX","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["From: lerxst@wam.umd.edu (where's my thing)\n","Subject: WHAT car is this!?\n","Nntp-Posting-Host: rac3.wam.umd.edu\n","Organization: University of Maryland, College Park\n","Lines: 15\n","\n"," I was wondering if anyone out there could enlighten me on this car I saw\n","the other day. It was a 2-door sports car, looked to be from the late 60s/\n","early 70s. It was called a Bricklin. The doors were really small. In addition,\n","the front bumper was separate from the rest of the body. This is \n","all I know. If anyone can tellme a model name, engine specs, years\n","of production, where this car is made, history, or whatever info you\n","have on this funky looking car, please e-mail.\n","\n","Thanks,\n","- IL\n","   ---- brought to you by your neighborhood Lerxst ----\n","\n","\n","\n","\n","\n"]}],"source":["print(newsgroups_train.data[0])"]},{"cell_type":"markdown","metadata":{"id":"A9-DD7wgCx8j"},"source":["Start by preprocessing the data for this tutorial in a Pandas dataframe. To remove any sensitive information like names and email addresses, you will take only the subject and body of each message. This is an optional step that transforms the input data into more generic text, rather than email posts, so that it will work in other contexts."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:45.171471Z","iopub.status.busy":"2024-11-08T20:12:45.17108Z","iopub.status.idle":"2024-11-08T20:12:45.633311Z","shell.execute_reply":"2024-11-08T20:12:45.632106Z","shell.execute_reply.started":"2024-11-08T20:12:45.171428Z"},"id":"urpLwp3UmPF3","trusted":true},"outputs":[],"source":["import email\n","import re\n","\n","import pandas as pd\n","\n","\n","def preprocess_newsgroup_row(data):\n","    # Extract only the subject and body\n","    msg = email.message_from_string(data)\n","    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n","    # Strip any remaining email addresses\n","    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n","    # Truncate each entry to 5,000 characters\n","    text = text[:5000]\n","\n","    return text\n","\n","\n","def preprocess_newsgroup_data(newsgroup_dataset):\n","    # Put data points into dataframe\n","    df = pd.DataFrame(\n","        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n","    )\n","    # Clean up the text\n","    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n","    # Match label to target name index\n","    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n","\n","    return df"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:45.636409Z","iopub.status.busy":"2024-11-08T20:12:45.635869Z","iopub.status.idle":"2024-11-08T20:12:49.656748Z","shell.execute_reply":"2024-11-08T20:12:49.655554Z","shell.execute_reply.started":"2024-11-08T20:12:45.63637Z"},"id":"JMKddQdNnAOV","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Label</th>\n","      <th>Class Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n","      <td>7</td>\n","      <td>rec.autos</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n","      <td>4</td>\n","      <td>comp.sys.mac.hardware</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n","      <td>4</td>\n","      <td>comp.sys.mac.hardware</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n","      <td>1</td>\n","      <td>comp.graphics</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n","      <td>14</td>\n","      <td>sci.space</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Text  Label  \\\n","0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n","1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n","2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n","3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n","4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n","\n","              Class Name  \n","0              rec.autos  \n","1  comp.sys.mac.hardware  \n","2  comp.sys.mac.hardware  \n","3          comp.graphics  \n","4              sci.space  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Apply preprocessing function to training and test datasets\n","df_train = preprocess_newsgroup_data(newsgroups_train)\n","df_test = preprocess_newsgroup_data(newsgroups_test)\n","\n","df_train.head()"]},{"cell_type":"markdown","metadata":{"id":"ogEGbg5XDv-T"},"source":["Next, you will sample some of the data by taking 100 data points in the training dataset, and dropping a few of the categories to run through this tutorial. Choose the science categories to compare."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:49.658768Z","iopub.status.busy":"2024-11-08T20:12:49.658327Z","iopub.status.idle":"2024-11-08T20:12:49.667682Z","shell.execute_reply":"2024-11-08T20:12:49.666427Z","shell.execute_reply.started":"2024-11-08T20:12:49.658717Z"},"id":"C2N7xXhJohLR","trusted":true},"outputs":[],"source":["def sample_data(df, num_samples, classes_to_keep):\n","    # Sample rows, selecting num_samples of each Label.\n","    df = (\n","        df.groupby(\"Label\")[df.columns]\n","        .apply(lambda x: x.sample(num_samples))\n","        .reset_index(drop=True)\n","    )\n","\n","    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n","\n","    # We have fewer categories now, so re-calibrate the label encoding.\n","    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n","    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n","\n","    return df"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:49.671765Z","iopub.status.busy":"2024-11-08T20:12:49.671358Z","iopub.status.idle":"2024-11-08T20:12:49.720168Z","shell.execute_reply":"2024-11-08T20:12:49.719068Z","shell.execute_reply.started":"2024-11-08T20:12:49.671725Z"},"id":"jS2g_ZGupBUb","trusted":true},"outputs":[],"source":["TRAIN_NUM_SAMPLES = 100\n","TEST_NUM_SAMPLES = 25\n","CLASSES_TO_KEEP = \"sci\"  # Class name should contain 'sci' to keep science categories\n","\n","df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n","df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:49.721871Z","iopub.status.busy":"2024-11-08T20:12:49.721522Z","iopub.status.idle":"2024-11-08T20:12:49.735025Z","shell.execute_reply":"2024-11-08T20:12:49.733824Z","shell.execute_reply.started":"2024-11-08T20:12:49.721835Z"},"id":"j04TMPY8rV5q","trusted":true},"outputs":[{"data":{"text/plain":["Class Name\n","sci.crypt          100\n","sci.electronics    100\n","sci.med            100\n","sci.space          100\n","Name: count, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df_train.value_counts(\"Class Name\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:49.737061Z","iopub.status.busy":"2024-11-08T20:12:49.736647Z","iopub.status.idle":"2024-11-08T20:12:49.747837Z","shell.execute_reply":"2024-11-08T20:12:49.746749Z","shell.execute_reply.started":"2024-11-08T20:12:49.737024Z"},"id":"qMsnfkVDsJlU","trusted":true},"outputs":[{"data":{"text/plain":["Class Name\n","sci.crypt          25\n","sci.electronics    25\n","sci.med            25\n","sci.space          25\n","Name: count, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df_test.value_counts(\"Class Name\")"]},{"cell_type":"markdown","metadata":{"id":"Kr-WlKzXjYWn"},"source":["## Create the embeddings\n","\n","In this section, you will generate embeddings for each piece of text using the Gemini API embeddings endpoint. To learn more about embeddings, visit the [embeddings guide](https://ai.google.dev/docs/embeddings_guide).\n","\n","**NOTE**: Embeddings are computed one at a time, so large sample sizes can take a long time!"]},{"cell_type":"markdown","metadata":{"id":"yPECMeE2xYA_"},"source":["### Task types\n","\n","The `text-embedding-004` model supports a task type parameter that generates embeddings tailored for the specific task.\n","\n","Task Type | Description\n","---       | ---\n","RETRIEVAL_QUERY\t| Specifies the given text is a query in a search/retrieval setting.\n","RETRIEVAL_DOCUMENT | Specifies the given text is a document in a search/retrieval setting.\n","SEMANTIC_SIMILARITY\t| Specifies the given text will be used for Semantic Textual Similarity (STS).\n","CLASSIFICATION\t| Specifies that the embeddings will be used for classification.\n","CLUSTERING\t| Specifies that the embeddings will be used for clustering.\n","FACT_VERIFICATION | Specifies that the given text will be used for fact verification.\n","\n","For this example you will be performing classification."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:49.749559Z","iopub.status.busy":"2024-11-08T20:12:49.749149Z","iopub.status.idle":"2024-11-08T20:12:49.760442Z","shell.execute_reply":"2024-11-08T20:12:49.759372Z","shell.execute_reply.started":"2024-11-08T20:12:49.749522Z"},"id":"MTBGKkPQsotz","trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","\n","tqdm.pandas()\n","\n","from google.api_core import retry\n","\n","\n","@retry.Retry(timeout=300.0)\n","def embed_fn(text: str) -> list[float]:\n","    # You will be performing classification, so set task_type accordingly.\n","    response = genai.embed_content(\n","        model=\"models/text-embedding-004\", content=text, task_type=\"classification\"\n","    )\n","\n","    return response[\"embedding\"]\n","\n","\n","def create_embeddings(df):\n","    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fn)\n","    return df"]},{"cell_type":"markdown","metadata":{"id":"HVDwY8F2kW2O"},"source":["This code is optimised for clarity, and is not particularly fast. It is left as an exercise for the reader to implement [batch](https://ai.google.dev/api/embeddings#method:-models.batchembedcontents) or parallel/asynchronous embedding generation. Running this step will take some time."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:12:49.762511Z","iopub.status.busy":"2024-11-08T20:12:49.762048Z","iopub.status.idle":"2024-11-08T20:15:13.043164Z","shell.execute_reply":"2024-11-08T20:15:13.041929Z","shell.execute_reply.started":"2024-11-08T20:12:49.762459Z"},"id":"AH0yrHUHtHtw","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 400/400 [01:17<00:00,  5.19it/s]\n","100%|██████████| 100/100 [00:19<00:00,  5.22it/s]\n"]}],"source":["df_train = create_embeddings(df_train)\n","df_test = create_embeddings(df_test)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:15:13.044785Z","iopub.status.busy":"2024-11-08T20:15:13.044434Z","iopub.status.idle":"2024-11-08T20:15:13.064043Z","shell.execute_reply":"2024-11-08T20:15:13.062556Z","shell.execute_reply.started":"2024-11-08T20:15:13.04475Z"},"id":"6G5TvLlmRjHc","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Label</th>\n","      <th>Class Name</th>\n","      <th>Encoded Label</th>\n","      <th>Embeddings</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1100</th>\n","      <td>Re: Is there ANY security in the Clipper?\\n\\nI...</td>\n","      <td>11</td>\n","      <td>sci.crypt</td>\n","      <td>0</td>\n","      <td>[0.004866375, 0.034185447, -0.04390365, 0.0230...</td>\n","    </tr>\n","    <tr>\n","      <th>1101</th>\n","      <td>Declassifying media\\n\\nThere are many Urban Le...</td>\n","      <td>11</td>\n","      <td>sci.crypt</td>\n","      <td>0</td>\n","      <td>[-0.0025853175, -0.0030856067, -0.05563356, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>1102</th>\n","      <td>(new) reason for Clipper alg'm secrecy\\n\\n[Apo...</td>\n","      <td>11</td>\n","      <td>sci.crypt</td>\n","      <td>0</td>\n","      <td>[0.011966013, -0.00066389417, -0.078864925, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>1103</th>\n","      <td>Pseudo-Random Character Generators (large stat...</td>\n","      <td>11</td>\n","      <td>sci.crypt</td>\n","      <td>0</td>\n","      <td>[0.012321499, 0.030036064, -0.054965224, 0.029...</td>\n","    </tr>\n","    <tr>\n","      <th>1104</th>\n","      <td>Re: The Escrow Database.\\n\\nIn article &lt;&gt;  (Ti...</td>\n","      <td>11</td>\n","      <td>sci.crypt</td>\n","      <td>0</td>\n","      <td>[-0.008613524, 0.033721704, -0.0431987, 0.0474...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   Text  Label Class Name  \\\n","1100  Re: Is there ANY security in the Clipper?\\n\\nI...     11  sci.crypt   \n","1101  Declassifying media\\n\\nThere are many Urban Le...     11  sci.crypt   \n","1102  (new) reason for Clipper alg'm secrecy\\n\\n[Apo...     11  sci.crypt   \n","1103  Pseudo-Random Character Generators (large stat...     11  sci.crypt   \n","1104  Re: The Escrow Database.\\n\\nIn article <>  (Ti...     11  sci.crypt   \n","\n","      Encoded Label                                         Embeddings  \n","1100              0  [0.004866375, 0.034185447, -0.04390365, 0.0230...  \n","1101              0  [-0.0025853175, -0.0030856067, -0.05563356, 0....  \n","1102              0  [0.011966013, -0.00066389417, -0.078864925, 0....  \n","1103              0  [0.012321499, 0.030036064, -0.054965224, 0.029...  \n","1104              0  [-0.008613524, 0.033721704, -0.0431987, 0.0474...  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df_train.head()"]},{"cell_type":"markdown","metadata":{"id":"QPYEYkIsWt_5"},"source":["## Build a simple classification model\n","\n","Here you will define a simple model that accepts the raw embedding data as input, has one hidden layer, and an output layer specifying the class probabilities. The prediction will correspond to the probability of a piece of text being a particular class of news.\n","\n","When you run the model, Keras will take care of details like shuffling the data points, calculating metrics and other ML boilerplate."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:15:13.065896Z","iopub.status.busy":"2024-11-08T20:15:13.065514Z","iopub.status.idle":"2024-11-08T20:15:24.975921Z","shell.execute_reply":"2024-11-08T20:15:24.974464Z","shell.execute_reply.started":"2024-11-08T20:15:13.065846Z"},"id":"3oLGi4w5JsQR","trusted":true},"outputs":[{"ename":"TypeError","evalue":"Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_classification_model\u001b[39m(input_size: \u001b[38;5;28mint\u001b[39m, num_classes: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel:\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\keras\\engine\\functional.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_pb2\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coordination_config_pb2\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node_def_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_node__def__pb2\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_def_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_op__def__pb2\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__pb2\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_handle_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow/core/framework/resource_handle.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[38;5;241m=\u001b[39m[tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,tensorflow_dot_core_dot_framework_dot_types__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,])\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36\u001b[0m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m     18\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     19\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m   serialized_pb\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m,tensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mz\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;124mTensorShapeProto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x64\u001b[39;00m\u001b[38;5;124mim\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[38;5;124m .tensorflow.TensorShapeProto.Dim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;124munknown_rank\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;130;01m\\x1a\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x44\u001b[39;00m\u001b[38;5;124mim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124msize\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124mname\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mB\u001b[39m\u001b[38;5;130;01m\\x87\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;124morg.tensorflow.frameworkB\u001b[39m\u001b[38;5;130;01m\\x11\u001b[39;00m\u001b[38;5;124mTensorShapeProtosP\u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[38;5;130;01m\\xf8\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     29\u001b[0m _TENSORSHAPEPROTO_DIM \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDim\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow.TensorShapeProto.Dim\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m   filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m   file\u001b[38;5;241m=\u001b[39mDESCRIPTOR,\n\u001b[0;32m     34\u001b[0m   containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m   fields\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m---> 36\u001b[0m     \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorflow.TensorShapeProto.Dim.size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menum_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     43\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     44\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow.TensorShapeProto.Dim.name\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     45\u001b[0m       number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, cpp_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     46\u001b[0m       has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, default_value\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     47\u001b[0m       message_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enum_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m       is_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, file\u001b[38;5;241m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     50\u001b[0m   ],\n\u001b[0;32m     51\u001b[0m   extensions\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     52\u001b[0m   ],\n\u001b[0;32m     53\u001b[0m   nested_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     54\u001b[0m   enum_types\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     55\u001b[0m   ],\n\u001b[0;32m     56\u001b[0m   serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m   is_extendable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     58\u001b[0m   syntax\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     59\u001b[0m   extension_ranges\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     60\u001b[0m   oneofs\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     61\u001b[0m   ],\n\u001b[0;32m     62\u001b[0m   serialized_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m149\u001b[39m,\n\u001b[0;32m     63\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m182\u001b[39m,\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m _TENSORSHAPEPROTO \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     67\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorShapeProto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     68\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow.TensorShapeProto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m182\u001b[39m,\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m _TENSORSHAPEPROTO_DIM\u001b[38;5;241m.\u001b[39mcontaining_type \u001b[38;5;241m=\u001b[39m _TENSORSHAPEPROTO\n","File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py:621\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[0;32m    616\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[0;32m    617\u001b[0m             is_extension, extension_scope, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    618\u001b[0m             serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    619\u001b[0m             has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    620\u001b[0m             file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m--> 621\u001b[0m   \u001b[43m_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _message\u001b[38;5;241m.\u001b[39mdefault_pool\u001b[38;5;241m.\u001b[39mFindExtensionByName(full_name)\n","\u001b[1;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"]}],"source":["import keras\n","from keras import layers\n","\n","\n","def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n","    return keras.Sequential(\n","        [\n","            layers.Input([input_size], name=\"embedding_inputs\"),\n","            layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n","            layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n","        ]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:15:24.977976Z","iopub.status.busy":"2024-11-08T20:15:24.977332Z","iopub.status.idle":"2024-11-08T20:15:25.090627Z","shell.execute_reply":"2024-11-08T20:15:25.089493Z","shell.execute_reply.started":"2024-11-08T20:15:24.977934Z"},"id":"kORA1Akl5GsG","trusted":true},"outputs":[],"source":["# Derive the embedding size from observing the data. The embedding size can also be specified\n","# with the `output_dimensionality` parameter to `embed_content` if you need to reduce it.\n","embedding_size = len(df_train[\"Embeddings\"].iloc[0])\n","\n","classifier = build_classification_model(\n","    embedding_size, len(df_train[\"Class Name\"].unique())\n",")\n","classifier.summary()\n","\n","classifier.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(),\n","    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n","    metrics=[\"accuracy\"],\n",")"]},{"cell_type":"markdown","metadata":{"id":"kbpTGGiMXDxl"},"source":["## Train the model\n","\n","Finally, you can train your model. This code uses early stopping to exit the training loop once the loss value stabilises, so the number of epoch loops executed may differ from the specified value."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:15:25.092379Z","iopub.status.busy":"2024-11-08T20:15:25.092009Z","iopub.status.idle":"2024-11-08T20:15:28.950529Z","shell.execute_reply":"2024-11-08T20:15:28.94935Z","shell.execute_reply.started":"2024-11-08T20:15:25.092341Z"},"id":"bGgvMZGfJ1A4","trusted":true},"outputs":[],"source":["import numpy as np\n","\n","\n","NUM_EPOCHS = 20\n","BATCH_SIZE = 32\n","\n","# Split the x and y components of the train and validation subsets.\n","y_train = df_train[\"Encoded Label\"]\n","x_train = np.stack(df_train[\"Embeddings\"])\n","y_val = df_test[\"Encoded Label\"]\n","x_val = np.stack(df_test[\"Embeddings\"])\n","\n","# Specify that it's OK to stop early if accuracy stabilises.\n","early_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n","\n","# Train the model for the desired number of epochs.\n","history = classifier.fit(\n","    x=x_train,\n","    y=y_train,\n","    validation_data=(x_val, y_val),\n","    callbacks=[early_stop],\n","    batch_size=BATCH_SIZE,\n","    epochs=NUM_EPOCHS,\n",")"]},{"cell_type":"markdown","metadata":{"id":"xGBaDHZUPdJO"},"source":["## Evaluate model performance\n","\n","Use Keras <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\"><code>Model.evaluate</code></a> to calculate the loss and accuracy on the test dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:15:28.952466Z","iopub.status.busy":"2024-11-08T20:15:28.952087Z","iopub.status.idle":"2024-11-08T20:15:29.046936Z","shell.execute_reply":"2024-11-08T20:15:29.045876Z","shell.execute_reply.started":"2024-11-08T20:15:28.952429Z"},"id":"d2kOeiqqQIB8","trusted":true},"outputs":[],"source":["classifier.evaluate(x=x_val, y=y_val, return_dict=True)"]},{"cell_type":"markdown","metadata":{"id":"UyxMhiLYQXAN"},"source":["To learn more about training models with Keras, including how to visualise the model training metrics, read [Training & evaluation with built-in methods](https://www.tensorflow.org/guide/keras/training_with_built_in_methods)."]},{"cell_type":"markdown","metadata":{"id":"XHyP-_torwsm"},"source":["## Try a custom prediction\n","\n","Now that you have a trained model with good evaluation metrics, you can try to make a prediction with new, hand-written data. Use the provided example or try your own data to see how the model performs."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:15:29.048527Z","iopub.status.busy":"2024-11-08T20:15:29.048171Z","iopub.status.idle":"2024-11-08T20:15:29.327605Z","shell.execute_reply":"2024-11-08T20:15:29.326451Z","shell.execute_reply.started":"2024-11-08T20:15:29.048492Z"},"id":"Lj4gR0Mdr2rb","trusted":true},"outputs":[],"source":["# This example avoids any space-specific terminology to see if the model avoids\n","# biases towards specific jargon.\n","new_text = \"\"\"\n","First-timer looking to get out of here.\n","\n","Hi, I'm writing about my interest in travelling to the outer limits!\n","\n","What kind of craft can I buy? What is easiest to access from this 3rd rock?\n","\n","Let me know how to do that please.\n","\"\"\"\n","embedded = embed_fn(new_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-08T20:15:29.330344Z","iopub.status.busy":"2024-11-08T20:15:29.329248Z","iopub.status.idle":"2024-11-08T20:15:29.441549Z","shell.execute_reply":"2024-11-08T20:15:29.440149Z","shell.execute_reply.started":"2024-11-08T20:15:29.33029Z"},"id":"CKTHEMrRsbcu","trusted":true},"outputs":[],"source":["# Remember that the model takes embeddings as input, and the input must be batched,\n","# so here they are passed as a list to provide a batch of 1.\n","inp = np.array([embedded])\n","[result] = classifier.predict(inp)\n","\n","for idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n","    print(f\"{category}: {result[idx] * 100:0.2f}%\")"]}],"metadata":{"colab":{"name":"day-2-classifying-embeddings-with-keras.ipynb","toc_visible":true},"google":{"image_path":"/examples/train_text_classifier_embeddings_files/output_3ae76701e178_0.png","keywords":["examples","googleai","samplecode","python","embed"]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}

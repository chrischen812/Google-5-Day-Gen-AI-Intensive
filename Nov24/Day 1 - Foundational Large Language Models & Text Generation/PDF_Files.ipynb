{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsDR_omdNea"
      },
      "source": [
        "# Gemini API: Read a PDF\n",
        "\n",
        "This notebook demonstrates how you can convert a PDF file so that it can be read by the Gemini API.\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb\"><img src=\"../images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaqZItBdeokU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XKJ78ne3O0sB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\chris\\miniconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uq \"google-generativeai>=0.7.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LUKlAk7iN_5e"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "import pathlib\n",
        "import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dteVdL4Y_t9"
      },
      "source": [
        "## Configure your API key\n",
        "\n",
        "To run the following cell, your API key must be stored in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "   \n",
        "   \n",
        "load_dotenv()\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A9sUQ4WrP-Yr"
      },
      "outputs": [],
      "source": [
        "#from google.colab import userdata \n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZj7pRt7exwE"
      },
      "source": [
        "## Download and inspect the PDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thYL8XGjerMa"
      },
      "source": [
        "Install the PDF processing tools. You don't need these to use the API, it's just used to display a screenshot of a page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WibRLdf2_Qoq"
      },
      "source": [
        "This PDF page is an article titled [Smoothly editing material properties of objects with text-to-image models and synthetic data](https://research.google/blog/smoothly-editing-material-properties-of-objects-with-text-to-image-models-and-synthetic-data/) available on the Google Research Blog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1k8Vy_1w1z6G"
      },
      "outputs": [],
      "source": [
        "if not pathlib.Path('test.pdf').exists():\n",
        "  !curl -o test.pdf https://storage.googleapis.com/generativeai-downloads/data/Smoothly%20editing%20material%20properties%20of%20objects%20with%20text-to-image%20models%20and%20synthetic%20data.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmIj4eQlfFot"
      },
      "source": [
        "Look at one of the pages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fH4WmrY_1MdQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'pdftoppm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pdftoppm test.pdf -f 1 -l 1 page-image -jpeg\n",
        "#%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "JGOg-cvK11IC"
      },
      "outputs": [],
      "source": [
        "import PIL.Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9b0MfUwc17Mk"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\chris\\\\Documents\\\\Projects\\\\GitHub R\\\\Google-5-Day-Gen-AI-Intensive\\\\Code\\\\Day 1 - Foundational Large Language Models & Text Generation\\\\page-image-1.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpage-image-1.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m img\u001b[38;5;241m.\u001b[39mthumbnail([\u001b[38;5;241m800\u001b[39m, \u001b[38;5;241m800\u001b[39m])\n\u001b[0;32m      3\u001b[0m img\n",
            "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\PIL\\Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\chris\\\\Documents\\\\Projects\\\\GitHub R\\\\Google-5-Day-Gen-AI-Intensive\\\\Code\\\\Day 1 - Foundational Large Language Models & Text Generation\\\\page-image-1.jpg'"
          ]
        }
      ],
      "source": [
        "img = PIL.Image.open(f\"page-image-1.jpg\")\n",
        "img.thumbnail([800, 800])\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhmqFY7o4eHM"
      },
      "source": [
        "## Upload the file to the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xgSJtXA427hF"
      },
      "outputs": [],
      "source": [
        "file_ref = genai.upload_file('test.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXFZFUJHgTcU"
      },
      "source": [
        "## Try it out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "c7f7ebc3dde9"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcFASSbqlTt5"
      },
      "source": [
        "The pages of the PDF file are each passed to the model as a screenshot of the page plus the text extracted by OCR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "be7VSZ7Q3UAR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "total_tokens: 4431"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.count_tokens([file_ref, '\\n\\nCan you summarize this file as a bulleted list?'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "123016f7809e"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    [file_ref, '\\n\\nCan you summarize this file as a bulleted list?']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "700bb45acbc8"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "This file contains a Google Research blog post about a new method that allows users to edit the material properties of objects in images using text-to-image models. \n",
              "\n",
              "- The method leverages a synthetic dataset to train a model to edit the material properties of objects in images, preserving the object's shape and image lighting. \n",
              "\n",
              "- This method can be used to make objects more metallic or transparent, change the roughness of an object, or even change the color of an object. \n",
              "\n",
              "- The model's potential use cases include interior design, product design, and even 3D reconstruction. \n",
              "\n",
              "- The researchers found that their method outperformed a baseline method in a user study.\n",
              "\n",
              "- This research is exciting because it demonstrates the potential of text-to-image models to be used for creative and practical applications. \n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvaVdm0utZdI"
      },
      "source": [
        "In addition, take a look at how the Gemini model responds when you ask questions about the images within the PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Dy1x48HmtfWB"
      },
      "outputs": [],
      "source": [
        "response_2 = model.generate_content(\n",
        "    [file_ref, '\\n\\nCan you explain the images on the first page of the document?']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rmzaDu3ht3xq"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The first page of the document shows a variety of examples of how a text-to-image model can be used to edit the material properties of objects in images. For example, in the first image, a user has asked the model to change the roughness of a teapot. The model has successfully changed the roughness of the teapot while preserving its overall shape and lighting. The other images show examples of how the model can be used to change the transparency, metallic appearance, and albedo of objects. \n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(response_2.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLlWUv21ucVb"
      },
      "source": [
        "If you observe the area of the header of the article, you can see that the model captures what is happening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93U69IwGujsM"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "The File API lets you upload a variety of multimodal MIME types, including images, audio, and video formats. The File API handles inputs that can be used to generate content with `model.generateContent` or `model.streamGenerateContent`.\n",
        "\n",
        "The File API accepts files under 2GB in size and can store up to 20GB of files per project. Files last for 2 days and cannot be downloaded from the API.\n",
        "\n",
        "* Learn more about the [File API](https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb) with the quickstart.\n",
        "\n",
        "* Learn more about prompting with [media files](https://ai.google.dev/gemini-api/docs/file-prompting-strategies) in the docs, including the supported formats and maximum length.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PDF_Files.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6e13eef3f5d"
   },
   "source": [
    "##### Copyright 2024 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-11-13T13:28:48.149451Z",
     "iopub.status.busy": "2024-11-13T13:28:48.148175Z",
     "iopub.status.idle": "2024-11-13T13:28:48.172942Z",
     "shell.execute_reply": "2024-11-13T13:28:48.17169Z",
     "shell.execute_reply.started": "2024-11-13T13:28:48.149391Z"
    },
    "id": "d6597b11df14",
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KDIFPAL2EnL"
   },
   "source": [
    "# Day 4 - Fine tuning a custom model\n",
    "\n",
    "Welcome back to the Kaggle 5-day Generative AI course!\n",
    "\n",
    "In this notebook you will use the Gemini API to fine-tune a custom, task-specific model. Fine-tuning can be used for a variety of tasks from classic NLP problems like entity extraction or summarisation, to creative tasks like stylised generation. You will fine-tune a model to classify the category a piece of text (a newsgroup post) into the category it belongs to (the newsgroup name).\n",
    "\n",
    "This codelab walks you tuning a model with the API. [AI Studio](https://aistudio.google.com/app/tune) also supports creating new tuned models directly in the web UI, allowing you to quickly create and monitor models using data from Google Sheets, Drive or your own files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:28:48.176078Z",
     "iopub.status.busy": "2024-11-13T13:28:48.175384Z",
     "iopub.status.idle": "2024-11-13T13:29:16.974112Z",
     "shell.execute_reply": "2024-11-13T13:29:16.972754Z",
     "shell.execute_reply.started": "2024-11-13T13:28:48.176022Z"
    },
    "id": "9wafTyEH1_xF",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'google-generativeai\"\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q 'google-generativeai>=0.8.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:16.976055Z",
     "iopub.status.busy": "2024-11-13T13:29:16.975693Z",
     "iopub.status.idle": "2024-11-13T13:29:18.197681Z",
     "shell.execute_reply": "2024-11-13T13:29:18.196518Z",
     "shell.execute_reply.started": "2024-11-13T13:29:16.976017Z"
    },
    "id": "T0CBG9xL2PvT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4bYX2T72ScK"
   },
   "source": [
    "### Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
    "\n",
    "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
    "\n",
    "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "   \n",
    "   \n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:18.200811Z",
     "iopub.status.busy": "2024-11-13T13:29:18.200296Z",
     "iopub.status.idle": "2024-11-13T13:29:18.503472Z",
     "shell.execute_reply": "2024-11-13T13:29:18.502516Z",
     "shell.execute_reply.started": "2024-11-13T13:29:18.200771Z"
    },
    "id": "VuJPY3GK2SLZ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "#GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b2127c2052"
   },
   "source": [
    "If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n",
    "\n",
    "![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqVA5QFO6n4z"
   },
   "source": [
    "### Explore available models\n",
    "\n",
    "You will be using the [`TunedModel.create`](https://ai.google.dev/api/tuning#method:-tunedmodels.create) API method to start the fine-tuning job and create your custom model. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about tuning models in [the model tuning docs](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object list_models at 0x0000025C58CAF430>\n"
     ]
    }
   ],
   "source": [
    "models = genai.list_models()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: module 'google.generativeai' has no attribute 'generate_text'. Please check if 'generate_text' is the correct method.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'medlm-large'  # Replace with the actual model name\n",
    "prompt = \"What are the symptoms of the common cold?\"\n",
    "\n",
    "try:\n",
    "    completion = genai.generate_text(model=model_name, prompt=prompt, max_output_tokens=100)\n",
    "    print(completion.result)\n",
    "except AttributeError as e:\n",
    "    print(f\"An error occurred: {e}. Please check if 'generate_text' is the correct method.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:18.505004Z",
     "iopub.status.busy": "2024-11-13T13:29:18.504654Z",
     "iopub.status.idle": "2024-11-13T13:29:19.362315Z",
     "shell.execute_reply": "2024-11-13T13:29:19.361055Z",
     "shell.execute_reply.started": "2024-11-13T13:29:18.504953Z"
    },
    "id": "coEacWAB6o0G",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.5-flash-001-tuning\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    if \"createTunedModel\" in model.supported_generation_methods:\n",
    "        print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peFm0w_0c1CO"
   },
   "source": [
    "## Download the dataset\n",
    "\n",
    "In this activity, you will use the same newsgroups dataset that you used to train a classifier in Keras. In this example you will use a fine-tuned Gemini model to achieve the same goal.\n",
    "\n",
    "The [20 Newsgroups Text Dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contains 18,000 newsgroups posts on 20 topics divided into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:19.363918Z",
     "iopub.status.busy": "2024-11-13T13:29:19.363585Z",
     "iopub.status.idle": "2024-11-13T13:29:42.921242Z",
     "shell.execute_reply": "2024-11-13T13:29:42.920044Z",
     "shell.execute_reply.started": "2024-11-13T13:29:19.363884Z"
    },
    "id": "bX_kpgnQ9b-Z",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipafe6ptZFjt"
   },
   "source": [
    "Here's what a single row looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:42.922817Z",
     "iopub.status.busy": "2024-11-13T13:29:42.922462Z",
     "iopub.status.idle": "2024-11-13T13:29:42.929029Z",
     "shell.execute_reply": "2024-11-13T13:29:42.927775Z",
     "shell.execute_reply.started": "2024-11-13T13:29:42.92278Z"
    },
    "id": "EtEXcdT39hCB",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03lDs1O4ZQ0-"
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "You'll use the same pre-processing code you used for the custom model on day 2. This pre-processing removes personal information, which can be used to \"shortcut\" to known users of a forum, and formats the text to appear a bit more like regular text and less like a newsgroup post (e.g. by removing the mail headers). This normalisation allows the model to generalise to regular text and not over-depend on specific fields. If your input data is always going to be newsgroup posts, it may be helpful to leave this structure in place if they provide genuine signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:42.931015Z",
     "iopub.status.busy": "2024-11-13T13:29:42.930578Z",
     "iopub.status.idle": "2024-11-13T13:29:43.39909Z",
     "shell.execute_reply": "2024-11-13T13:29:43.397848Z",
     "shell.execute_reply.started": "2024-11-13T13:29:42.930946Z"
    },
    "id": "IoNYTxpoZgB0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # Extract only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncate the text to fit within the input limits\n",
    "    text = text[:40000]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Put data points into dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
    "    )\n",
    "    # Clean up the text\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Match label to target name index\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:43.401035Z",
     "iopub.status.busy": "2024-11-13T13:29:43.400499Z",
     "iopub.status.idle": "2024-11-13T13:29:47.428248Z",
     "shell.execute_reply": "2024-11-13T13:29:47.427184Z",
     "shell.execute_reply.started": "2024-11-13T13:29:43.400975Z"
    },
    "id": "kvOsUSRWaW4g",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSKcj5WtadaR"
   },
   "source": [
    "Now sample the data. You will keep 50 rows for each category for training. Note that this is even fewer than the Keras example, as this technique (parameter-efficient fine-tuning, or PEFT) updates a relatively small number of parameters and does not require training a new model or updating the large model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:47.433856Z",
     "iopub.status.busy": "2024-11-13T13:29:47.433303Z",
     "iopub.status.idle": "2024-11-13T13:29:47.487358Z",
     "shell.execute_reply": "2024-11-13T13:29:47.486167Z",
     "shell.execute_reply.started": "2024-11-13T13:29:47.433815Z"
    },
    "id": "0t9Xu6X5akkt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Sample rows, selecting num_samples of each Label.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "TRAIN_NUM_SAMPLES = 50\n",
    "TEST_NUM_SAMPLES = 10\n",
    "# Keep rec.* and sci.*\n",
    "CLASSES_TO_KEEP = \"^rec|^sci\"\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate baseline performance\n",
    "\n",
    "Before you start tuning a model, it's good practice to perform an evaluation on the available models to ensure you can measure how much the tuning helps.\n",
    "\n",
    "First identify a single sample row to use for visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:47.489557Z",
     "iopub.status.busy": "2024-11-13T13:29:47.489088Z",
     "iopub.status.idle": "2024-11-13T13:29:47.496912Z",
     "shell.execute_reply": "2024-11-13T13:29:47.495694Z",
     "shell.execute_reply.started": "2024-11-13T13:29:47.489506Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need info on 88-89 Bonneville\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "---\n",
      "Label: rec.autos\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "sample_row = preprocess_newsgroup_row(newsgroups_test.data[sample_idx])\n",
    "sample_label = newsgroups_test.target_names[newsgroups_test.target[sample_idx]]\n",
    "\n",
    "print(sample_row)\n",
    "print('---')\n",
    "print('Label:', sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the text directly in as a prompt does not yield the desired results. The model will attempt to respond to the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:47.499016Z",
     "iopub.status.busy": "2024-11-13T13:29:47.498513Z",
     "iopub.status.idle": "2024-11-13T13:29:50.820418Z",
     "shell.execute_reply": "2024-11-13T13:29:50.819133Z",
     "shell.execute_reply.started": "2024-11-13T13:29:47.498949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 1988-1989 Pontiac Bonneville: Model Breakdown\n",
      "\n",
      "You're right, the 1988-1989 Bonnevilles can be a bit confusing with their different trim levels. Here's a breakdown:\n",
      "\n",
      "**Base Model:** This was the standard Bonneville with a 3.8L V6 engine and a 3-speed automatic transmission. It had basic features like cloth upholstery, vinyl roof, and power steering.\n",
      "\n",
      "**LE (Luxury Edition):** The LE added more luxury features like plusher interior, power windows, power locks, and a 4-speed automatic transmission.\n",
      "\n",
      "**SE (Sport Edition):**  This model had a sportier exterior with a more aggressive grille and wheels, and often had the 3.8L V6 engine. However, some SE models came with the optional 5.0L V8 engine, giving them a considerable power boost.\n",
      "\n",
      "**LSE (Luxury Sport Edition):** This combined the luxury features of the LE with the sporty exterior of the SE. They typically had the 3.8L V6 engine, but the 5.0L V8 was an option.\n",
      "\n",
      "**SSE (Sport Sedan Edition):**  The SSE was the top-of-the-line performance model. It always came with the powerful 5.0L V8 engine, sporty suspension, and a variety of other performance upgrades.\n",
      "\n",
      "**SSEi (Sport Sedan Edition - Injected):** This model was essentially the same as the SSE but with a fuel-injected 5.0L V8 engine for better fuel efficiency and performance.\n",
      "\n",
      "**Key Differences:**\n",
      "\n",
      "* **Engine:** The main difference between models was the engine. Base, LE, and SE models typically came with the 3.8L V6, while the SSE and SSEi had the 5.0L V8.\n",
      "* **Features:** The higher trim levels (LE, LSE, SSE, SSEi) generally came with more luxury and comfort features like leather upholstery, power seats, and upgraded sound systems.\n",
      "\n",
      "## 1989 Bonneville Book Value and Pricing\n",
      "\n",
      "Unfortunately, I cannot provide specific book values or pricing information. This data is subject to many variables, including:\n",
      "\n",
      "* **Condition:** The overall condition of the car (mileage, maintenance, accident history) will heavily influence its value.\n",
      "* **Location:** Prices can vary depending on your geographic location and regional demand.\n",
      "* **Specific model and options:** Features like engine size, transmission, and options can affect the price.\n",
      "\n",
      "**Resources for finding values:**\n",
      "\n",
      "* **Kelly Blue Book (KBB):** [https://www.kbb.com](https://www.kbb.com)\n",
      "* **Edmunds:** [https://www.edmunds.com](https://www.edmunds.com)\n",
      "* **NADA Guides:** [https://www.nadaguides.com](https://www.nadaguides.com)\n",
      "\n",
      "These websites will allow you to input the specific details of your 1989 Bonneville and get an estimate of its current market value.\n",
      "\n",
      "**Negotiating Price:**\n",
      "\n",
      "You are correct that mid-spring to early summer can be a good time to buy a car, as dealerships are looking to clear inventory for newer models.  However, the actual negotiation process is a skill. Here are some tips:\n",
      "\n",
      "* **Research:** Know the current market value for your desired model and condition.\n",
      "* **Be patient:** Don't rush into a purchase. Take your time and shop around.\n",
      "* **Be prepared to walk away:** Don't be afraid to walk away from a deal if you don't feel it's fair.\n",
      "* **Negotiate firmly but respectfully:** Be confident in your position but avoid being aggressive.\n",
      "\n",
      "Good luck in your search for a 1989 Pontiac Bonneville! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_model = genai.GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "response = baseline_model.generate_content(sample_row)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the prompt engineering techniques you have learned this week to induce the model to perform the desired task. Try some of your own ideas and see what is effective, or check out the following cells for different approaches. Note that they have different levels of effectiveness!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:50.822275Z",
     "iopub.status.busy": "2024-11-13T13:29:50.821882Z",
     "iopub.status.idle": "2024-11-13T13:29:53.322475Z",
     "shell.execute_reply": "2024-11-13T13:29:53.321259Z",
     "shell.execute_reply.started": "2024-11-13T13:29:50.822235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the content of the message, it is most likely from a **Buick-specific newsgroup**, possibly **alt.autos.buick**.  \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Specific Model:** The message specifically mentions the 1988-89 Buick Bonneville, a popular model for the time.\n",
      "* **Trim Levels:** The question refers to various trim levels (LE, SE, LSE, SSE, SSEi), all of which were specific to the Bonneville during that era.\n",
      "* **Value and Market:**  The inquiry about book value and market demand points to a car-related discussion, and the mention of mid-spring/early summer as a good buying time is common car buying advice.\n",
      "\n",
      "While there may be other newsgroups where this message could appear, **alt.autos.buick** is the most fitting based on the topic's specificity. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask the model directly in a zero-shot prompt.\n",
    "\n",
    "prompt = \"From what newsgroup does the following message originate?\"\n",
    "baseline_response = baseline_model.generate_content([prompt, sample_row])\n",
    "print(baseline_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That technique produces quite a verbose response. You could try and pick out the relevant text, or refine the prompt even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:53.324333Z",
     "iopub.status.busy": "2024-11-13T13:29:53.323845Z",
     "iopub.status.idle": "2024-11-13T13:29:53.933051Z",
     "shell.execute_reply": "2024-11-13T13:29:53.931673Z",
     "shell.execute_reply.started": "2024-11-13T13:29:53.324285Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos.misc\n",
      "\n",
      "Incorrect.\n"
     ]
    }
   ],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "# You can use a system instruction to do more direct prompting, and get a\n",
    "# more succinct answer.\n",
    "\n",
    "system_instruct = \"\"\"\n",
    "You are a classification service. You will be passed input that represents\n",
    "a newsgroup post and you must respond with the newsgroup from which the post\n",
    "originates.\n",
    "\"\"\"\n",
    "\n",
    "instructed_model = genai.GenerativeModel(\"gemini-1.5-flash-001\",\n",
    "                                         system_instruction=system_instruct)\n",
    "\n",
    "retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "# If you want to evaluate your own technique, replace this function with your\n",
    "# model, prompt and other code and return the predicted answer.\n",
    "def predict_label(post: str) -> str:\n",
    "    response = instructed_model.generate_content(sample_row, request_options=retry_policy)\n",
    "    # Clean up the response.\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "prediction = predict_label(sample_row)\n",
    "\n",
    "print(prediction)\n",
    "print()\n",
    "print(\"Correct!\" if prediction == sample_label else \"Incorrect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run a short evaluation using the function defined above. The test set is further sampled to ensure the experiment runs smoothly on the API's free tier. In practice you would evaluate over the whole set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:29:53.93523Z",
     "iopub.status.busy": "2024-11-13T13:29:53.934695Z",
     "iopub.status.idle": "2024-11-13T13:31:09.697177Z",
     "shell.execute_reply": "2024-11-13T13:31:09.69595Z",
     "shell.execute_reply.started": "2024-11-13T13:29:53.935177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754b1b46d34b428e84494cfc6f652101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\miniconda3\\lib\\site-packages\\tqdm\\std.py:773: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  t = cls(total=total, **tqdm_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.rich import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "# Further sample the test data to be mindful of the free-tier quota.\n",
    "df_baseline_eval = sample_data(df_test, 2, '.*')\n",
    "\n",
    "# Make predictions using the sampled data.\n",
    "df_baseline_eval['Prediction'] = df_baseline_eval['Text'].progress_apply(predict_label)\n",
    "\n",
    "# And calculate the accuracy.\n",
    "accuracy = (df_baseline_eval[\"Class Name\"] == df_baseline_eval[\"Prediction\"]).sum() / len(df_baseline_eval)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the dataframe to compare the predictions with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:31:09.698834Z",
     "iopub.status.busy": "2024-11-13T13:31:09.698482Z",
     "iopub.status.idle": "2024-11-13T13:31:09.712937Z",
     "shell.execute_reply": "2024-11-13T13:31:09.71156Z",
     "shell.execute_reply.started": "2024-11-13T13:31:09.698782Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: MR2 - noisy engine.\\n\\nIn article &lt;&gt;,  (el...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Info about Audi 90 (used)\\n\\nI am thinking of ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re: BMW heated grips\\n\\nIn article &lt;&gt;  (Art Ca...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volvo Attack!\\n\\nI was privelged enough to exp...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>rec.autos.pontiac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Box score abbrev woes\\n\\nIn article &lt;&gt;  (j...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Re: How does a pitcher get a save?\\n\\nIn artic...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Islanders win Third in OT\\n\\nDon't know who sc...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>rec.autos.pontiac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AHL Leafs Back Home?\\n\\nApparently, the public...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Re: new encryption\\n\\nIn article &lt;&gt;  (David St...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Re: triple des\\n\\n\\nPlease post to news, too.\\...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Re: **** And now serious: E-Magazine *****\\n\\n...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Re: Radar detector DETECTORS?\\n\\nIn article &lt;&gt;...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Re: vitamin A and hearing loss\\n\\nIn article &lt;...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Re: Quack-Quack (was Re: Candida(yeast) Bloom,...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Re: Life on Mars.\\n\\nIn article &lt;&gt;  (Eric H Se...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RE: Commercials on the Moon\\n\\n (Hans Erik Mar...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>rec.autos.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label  \\\n",
       "0   Re: MR2 - noisy engine.\\n\\nIn article <>,  (el...      7   \n",
       "1   Info about Audi 90 (used)\\n\\nI am thinking of ...      7   \n",
       "2   Re: BMW heated grips\\n\\nIn article <>  (Art Ca...      8   \n",
       "3   Volvo Attack!\\n\\nI was privelged enough to exp...      8   \n",
       "4   Re: Box score abbrev woes\\n\\nIn article <>  (j...      9   \n",
       "5   Re: How does a pitcher get a save?\\n\\nIn artic...      9   \n",
       "6   Islanders win Third in OT\\n\\nDon't know who sc...     10   \n",
       "7   AHL Leafs Back Home?\\n\\nApparently, the public...     10   \n",
       "8   Re: new encryption\\n\\nIn article <>  (David St...     11   \n",
       "9   Re: triple des\\n\\n\\nPlease post to news, too.\\...     11   \n",
       "10  Re: **** And now serious: E-Magazine *****\\n\\n...     12   \n",
       "11  Re: Radar detector DETECTORS?\\n\\nIn article <>...     12   \n",
       "12  Re: vitamin A and hearing loss\\n\\nIn article <...     13   \n",
       "13  Re: Quack-Quack (was Re: Candida(yeast) Bloom,...     13   \n",
       "14  Re: Life on Mars.\\n\\nIn article <>  (Eric H Se...     14   \n",
       "15  RE: Commercials on the Moon\\n\\n (Hans Erik Mar...     14   \n",
       "\n",
       "            Class Name         Prediction  \n",
       "0            rec.autos     rec.autos.misc  \n",
       "1            rec.autos     rec.autos.misc  \n",
       "2      rec.motorcycles     rec.autos.misc  \n",
       "3      rec.motorcycles  rec.autos.pontiac  \n",
       "4   rec.sport.baseball     rec.autos.misc  \n",
       "5   rec.sport.baseball     rec.autos.misc  \n",
       "6     rec.sport.hockey  rec.autos.pontiac  \n",
       "7     rec.sport.hockey     rec.autos.misc  \n",
       "8            sci.crypt     rec.autos.misc  \n",
       "9            sci.crypt     rec.autos.misc  \n",
       "10     sci.electronics     rec.autos.misc  \n",
       "11     sci.electronics     rec.autos.misc  \n",
       "12             sci.med     rec.autos.misc  \n",
       "13             sci.med     rec.autos.misc  \n",
       "14           sci.space     rec.autos.misc  \n",
       "15           sci.space     rec.autos.misc  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok7ugrLzcghX"
   },
   "source": [
    "## Tune a custom model\n",
    "\n",
    "In this example you'll use tuning to help create a model that requires no prompting or system instructions and outputs succinct text from the classes you provide in the training data.\n",
    "\n",
    "The data contains both input text (the processed posts) and output text (the category, or newsgroup), which you can use to start tuning a model.\n",
    "\n",
    "The Python SDK for tuning supports Pandas dataframes as input, so you don't need any custom data generators or pipelines. Just specify the input and the relevant columns as the `input_key` and `output_key`.\n",
    "\n",
    "When calling `create_tuned_model`, you can specify model tuning hyperparameters too:\n",
    " - `epoch_count`: defines how many times to loop through the data,\n",
    " - `batch_size`: defines how many rows to process in a single step, and\n",
    " - `learning_rate`: defines the scaling factor for updating model weights at each step.\n",
    "\n",
    "You can also choose to omit them and use the defaults. [Learn more](https://developers.google.com/machine-learning/crash-course/linear-regression/hyperparameters) about these parameters and how they work. For this example these parameters were selected by running some tuning jobs and selecting parameters that were both effective and quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:31:09.715061Z",
     "iopub.status.busy": "2024-11-13T13:31:09.714568Z",
     "iopub.status.idle": "2024-11-13T13:31:11.250415Z",
     "shell.execute_reply": "2024-11-13T13:31:11.249279Z",
     "shell.execute_reply.started": "2024-11-13T13:31:09.715007Z"
    },
    "id": "pWOZlspfY8dV",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup-classifier-14243\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Iterable\n",
    "import random\n",
    "\n",
    "\n",
    "# Append a random number to the model ID so you can re-run with a higher chance\n",
    "# of creating a unique model ID.\n",
    "model_id = f\"newsgroup-classifier-{random.randint(10000, 99999)}\"\n",
    "\n",
    "# Upload the training data and queue the tuning job.\n",
    "tuning_op = genai.create_tuned_model(\n",
    "    \"models/gemini-1.5-flash-001-tuning\",\n",
    "    training_data=df_train,\n",
    "    input_key=\"Text\",  # the column to use as input\n",
    "    output_key=\"Class Name\",  # the column to use as output\n",
    "    id=model_id,\n",
    "    display_name=\"Newsgroup classification model\",\n",
    "    batch_size=16,\n",
    "    epoch_count=2,\n",
    ")\n",
    "\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ3YZ2MBubCY"
   },
   "source": [
    "This has created a tuning job that will run in the background. To inspect the progress of the tuning job, run this cell to plot the current status and loss curve. Once the status reaches `ACTIVE`, tuning is complete and the model is ready to use.\n",
    "\n",
    "Tuning jobs are queued, so it may look like no training steps have been taken initially but it will progress. Tuning can take upwards of 20 minutes, depending on factors like your dataset size and how busy the tuning infrastrature is. Why not treat yourself to a nice cup of tea while you wait, or come and say \"Hi!\" to [yours truly](https://discord.com/users/132124213132787712) in the group [Discord](https://discord.com/invite/kaggle).\n",
    "\n",
    "It is safe to stop this cell at any point. It will not stop the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:31:11.252493Z",
     "iopub.status.busy": "2024-11-13T13:31:11.252011Z",
     "iopub.status.idle": "2024-11-13T13:37:15.16925Z",
     "shell.execute_reply": "2024-11-13T13:37:15.168064Z",
     "shell.execute_reply.started": "2024-11-13T13:31:11.25244Z"
    },
    "id": "c4ef5f13692d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State.CREATING\n",
      "State.CREATING\n",
      "State.CREATING\n",
      "State.CREATING\n",
      "State.CREATING\n",
      "Done! The model is ACTIVE\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "while (tuned_model := genai.get_tuned_model(f\"tunedModels/{model_id}\")).state.name != 'ACTIVE':\n",
    "\n",
    "    if tuned_model.tuning_task.snapshots:\n",
    "        # If the tuning task has started, this will draw the loss so far.\n",
    "        snapshots = pd.DataFrame(tuned_model.tuning_task.snapshots)\n",
    "        sns.lineplot(data=snapshots, x=\"step\", y=\"mean_loss\")\n",
    "    \n",
    "    print(tuned_model.state)\n",
    "\n",
    "    time.sleep(60)\n",
    "\n",
    "print(f\"Done! The model is {tuned_model.state.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-qiIdK4u80z"
   },
   "source": [
    "## Use the new model\n",
    "\n",
    "Now that you have a tuned model, try it out with custom data. You use the same API as a normal Gemini API interaction, but you specify your new model as the model name, using the `tunedModels/` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:37:15.171553Z",
     "iopub.status.busy": "2024-11-13T13:37:15.170866Z",
     "iopub.status.idle": "2024-11-13T13:37:17.653369Z",
     "shell.execute_reply": "2024-11-13T13:37:17.652196Z",
     "shell.execute_reply.started": "2024-11-13T13:37:15.171512Z"
    },
    "id": "hyO2-MXLvM6a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n"
     ]
    }
   ],
   "source": [
    "your_model = genai.GenerativeModel(f\"tunedModels/{model_id}\")\n",
    "\n",
    "new_text = \"\"\"\n",
    "First-timer looking to get out of here.\n",
    "\n",
    "Hi, I'm writing about my interest in travelling to the outer limits!\n",
    "\n",
    "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
    "\n",
    "Let me know how to do that please.\n",
    "\"\"\"\n",
    "\n",
    "response = your_model.generate_content(new_text)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xajLek9DySH_"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "You can see that the model outputs labels that correspond to those in the training data, and without any system instructions or prompting, which is already a great improvement. Now see how well it performs on the test set.\n",
    "\n",
    "Note that there is no parallelism in this example; classifying the test sub-set will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:37:17.655022Z",
     "iopub.status.busy": "2024-11-13T13:37:17.654649Z",
     "iopub.status.idle": "2024-11-13T13:38:36.569011Z",
     "shell.execute_reply": "2024-11-13T13:38:36.567728Z",
     "shell.execute_reply.started": "2024-11-13T13:37:17.654969Z"
    },
    "id": "6T2Y3ZApvbMw",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684cebc22d804101a06262f5b05553f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\miniconda3\\lib\\site-packages\\tqdm\\std.py:773: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  t = cls(total=total, **tqdm_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "def classify_text(text: str) -> str:\n",
    "    \"\"\"Classify the provided text into a known newsgroup.\"\"\"\n",
    "    response = your_model.generate_content(text, request_options=retry_policy)\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Any errors, filters, recitation, etc we can mark as a general error\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        return rc.content.parts[0].text\n",
    "\n",
    "\n",
    "# The sampling here is just to minimise your quota usage. If you can, you should\n",
    "# evaluate the whole test set with `df_model_eval = df_test.copy()`.\n",
    "df_model_eval = sample_data(df_test, 4, '.*')\n",
    "\n",
    "\n",
    "df_model_eval[\"Prediction\"] = df_model_eval[\"Text\"].progress_apply(classify_text)\n",
    "\n",
    "accuracy = (df_model_eval[\"Class Name\"] == df_model_eval[\"Prediction\"]).sum() / len(df_model_eval)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare token usage\n",
    "\n",
    "AI Studio and the Gemini API provide model tuning at no cost, however normal limits and charges apply for *use* of a tuned model.\n",
    "\n",
    "The size of the input prompt and other generation config like system instructions, as well as the number of generated output tokens, all contribute to the overall cost of a request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:43:42.056128Z",
     "iopub.status.busy": "2024-11-13T13:43:42.055653Z",
     "iopub.status.idle": "2024-11-13T13:43:42.660039Z",
     "shell.execute_reply": "2024-11-13T13:43:42.658403Z",
     "shell.execute_reply.started": "2024-11-13T13:43:42.056083Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System instructed baseline model: 171 (input)\n",
      "Tuned model: 135 (input)\n",
      "Token savings: 26.67%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the *input* cost of the baseline model with system instructions.\n",
    "sysint_tokens = instructed_model.count_tokens(sample_row).total_tokens\n",
    "print(f'System instructed baseline model: {sysint_tokens} (input)')\n",
    "\n",
    "# Calculate the input cost of the tuned model.\n",
    "tuned_tokens = your_model.count_tokens(sample_row).total_tokens\n",
    "print(f'Tuned model: {tuned_tokens} (input)')\n",
    "\n",
    "savings = (sysint_tokens - tuned_tokens) / tuned_tokens\n",
    "print(f'Token savings: {savings:.2%}')  # Note that this is only n=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earlier verbose model also produced more output tokens than needed for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T13:43:48.374771Z",
     "iopub.status.busy": "2024-11-13T13:43:48.37436Z",
     "iopub.status.idle": "2024-11-13T13:43:49.500893Z",
     "shell.execute_reply": "2024-11-13T13:43:49.499626Z",
     "shell.execute_reply.started": "2024-11-13T13:43:48.374733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (verbose) output tokens: 184\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m baseline_token_output \u001b[38;5;241m=\u001b[39m baseline_response\u001b[38;5;241m.\u001b[39musage_metadata\u001b[38;5;241m.\u001b[39mcandidates_token_count\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaseline (verbose) output tokens:\u001b[39m\u001b[38;5;124m'\u001b[39m, baseline_token_output)\n\u001b[1;32m----> 4\u001b[0m tuned_model_output \u001b[38;5;241m=\u001b[39m \u001b[43myour_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_row\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m tuned_tokens_output \u001b[38;5;241m=\u001b[39m tuned_model_output\u001b[38;5;241m.\u001b[39musage_metadata\u001b[38;5;241m.\u001b[39mcandidates_token_count\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTuned output tokens:\u001b[39m\u001b[38;5;124m'\u001b[39m, tuned_tokens_output)\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\miniconda3\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "baseline_token_output = baseline_response.usage_metadata.candidates_token_count\n",
    "print('Baseline (verbose) output tokens:', baseline_token_output)\n",
    "\n",
    "tuned_model_output = your_model.generate_content(sample_row)\n",
    "tuned_tokens_output = tuned_model_output.usage_metadata.candidates_token_count\n",
    "print('Tuned output tokens:', tuned_tokens_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c1204a5d0ab"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Now that you have tuned a classification model, try some other tasks, like tuning a model to respond with a specific tone or style using hand-written examples (or even generated examples!). Kaggle hosts [a number of datasets](https://www.kaggle.com/datasets) you can try out.\n",
    "\n",
    "Learn about [when supervised fine-tuning is most effective](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm).\n",
    "\n",
    "And check out the [fine-tuning tutorial](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?hl=en&lang=python) for another example that shows a tuned model extending beyond the training data to new, unseen inputs."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "day-4-fine-tuning-a-custom-model.ipynb",
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
